{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (My_GAT.py, line 12)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3417\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-57b553e2b198>\"\u001b[0;36m, line \u001b[0;32m21\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from models.My_GAT import My_GAT\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/home/sandra/PROGRAMAS/DBU_Graph/models/My_GAT.py\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    def __init__(self, in_feats, out_feats, bn=True feat_drop=0., attn_drop=0.):\u001b[0m\n\u001b[0m                                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "os.environ['DGLBACKEND'] = 'pytorch'\n",
    "from dgl import DGLGraph\n",
    "import numpy as np\n",
    "import scipy.sparse as spp\n",
    "from scipy import spatial\n",
    "from tqdm import tqdm\n",
    "from dgl.data import DGLDataset\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from ApolloScape_Dataset import ApolloScape_DGLDataset\n",
    "import pytorch_lightning as pl\n",
    "import wandb\n",
    "from models.My_GAT import My_GAT\n",
    "from models.GCN import GCN\n",
    "from models.GatedGCN import GatedGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ApolloScape_DGLDataset(train_val='train') #3447\n",
    "val_dataset = ApolloScape_DGLDataset(train_val='val')  #919\n",
    "test_dataset = ApolloScape_DGLDataset(train_val='test')  #230\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 6, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collate function to prepare graphs\n",
    "def collate_batch(samples):\n",
    "    graphs, masks = map(list, zip(*samples))  # samples is a list of pairs (graph, mask) mask es VxTx1\n",
    "    masks = np.vstack(masks)\n",
    "    masks = torch.tensor(masks)#+torch.zeros(2)\n",
    "    #masks = masks.view(masks.shape[0],-1)\n",
    "    #masks= masks.view(masks.shape[0]*masks.shape[1],masks.shape[2],masks.shape[3])#.squeeze(0) para TAMAÑO FIJO\n",
    "    sizes_n = [graph.number_of_nodes() for graph in graphs] # graph sizes\n",
    "    snorm_n = [torch.FloatTensor(size, 1).fill_(1 / size) for size in sizes_n]\n",
    "    snorm_n = torch.cat(snorm_n).sqrt()  # graph size normalization \n",
    "    sizes_e = [graph.number_of_edges() for graph in graphs] # nb of edges\n",
    "    snorm_e = [torch.FloatTensor(size, 1).fill_(1 / size) for size in sizes_e]\n",
    "    snorm_e = torch.cat(snorm_e).sqrt()  # graph size normalization\n",
    "    batched_graph = dgl.batch(graphs)  # batch graphs\n",
    "    return batched_graph, masks, snorm_n, snorm_e\n",
    "\n",
    "\n",
    "dev='cuda'\n",
    "batch_size=64\n",
    "train_dataloader=DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=8, collate_fn=collate_batch)\n",
    "val_dataloader=DataLoader(val_dataset, batch_size=batch_size, shuffle=False,  num_workers=8, collate_fn=collate_batch)\n",
    "test_dataloader=DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=8, collate_fn=collate_batch)  \n",
    "batched_graph, masks, snorm_n, snorm_e=next(iter(test_dataloader))\n",
    "masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 6])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks.sum(dim=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "batched_graph, masks, snorm_n, snorm_e, last_vis_obj=next(iter(test_dataloader))\n",
    "print(masks.shape)\n",
    "ori_data=batched_graph.ndata['x'].float()\n",
    "data = ori_data.detach().clone().cpu().numpy()\n",
    "print(data[:,:,0])\n",
    "\n",
    "#new_mask = (data[:, 1:,:2]!=0) * (data[:, :-1, :2]!=0) \n",
    "#data[:, 1:,:2] = (data[:, 1:,:2] - data[:, :-1, :2]).float() * new_mask.float()\n",
    "#data[:, 0, :2] = 0\n",
    "'''\n",
    "rescale_xy = torch.ones((1,1,2)).to(dev)\n",
    "rescale_xy[:,:,0] = torch.max(abs(data[:,:,0]))\n",
    "rescale_xy[:,:,1] = torch.max(abs(data[:,:,1]))\n",
    "data[:,:,:2]=data[:,:,:2]/rescale_xy\n",
    "print(data[0])\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../DBU_Graph/data/apollo_train_data.pkl', 'rb') as reader:\n",
    "    [feat,adj, mean]=pickle.load(reader)\n",
    "    \n",
    "feat=np.transpose(feat, (0,3,2,1))\n",
    "print(feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#pruebas def preprocess_data de main.py (GRIP) \n",
    "feature_id = [3, 4, 9, 10]  #x,y,heading,[visible_mask]\n",
    "vel_data = feat[:,feature_id]  # N,C,T,V\n",
    "vel_mask = (vel_data[:, :2, 1:]!=0) * (vel_data[:, :2, :-1]!=0) #False-> frames en los que no tenemos VELOCIDAD del obj\n",
    "vel_data[:, :2, 1:] = (vel_data[:, :2, 1:] - vel_data[:, :2, :-1]).astype(float) * vel_mask.astype(float)\n",
    "vel_data[:, :2, 0] = 0\n",
    "print(vel_data[0,:,6:,0])\n",
    "#print(new_mask[0,:,:,0])\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5010, 70, 12, 11])\n"
     ]
    }
   ],
   "source": [
    "features=torch.from_numpy(feat[:,:70,:,:]).type(torch.float32)\n",
    "#print(features.shape)\n",
    "\n",
    "last_vis_obj_i=[]   #contains number of visible obj in each sequence of the training\n",
    "\n",
    "for idx in range(len(adj)): \n",
    "    for i in range(len(adj[idx])): \n",
    "        if adj[idx][i,i] == 0:\n",
    "            last_vis_obj_i.append(i)\n",
    "            break   \n",
    "            \n",
    "last_vis_obj_i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_dpi_ratio', { dpi_ratio: fig.ratio });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "    if (this.ratio !== 1) {\n",
       "        fig.send_message('set_dpi_ratio', { dpi_ratio: this.ratio });\n",
       "    }\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    var resizeObserver = new ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    resizeObserver.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch (cursor) {\n",
       "        case 0:\n",
       "            cursor = 'pointer';\n",
       "            break;\n",
       "        case 1:\n",
       "            cursor = 'default';\n",
       "            break;\n",
       "        case 2:\n",
       "            cursor = 'crosshair';\n",
       "            break;\n",
       "        case 3:\n",
       "            cursor = 'move';\n",
       "            break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = 'image/png';\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * this.ratio;\n",
       "    var y = canvas_pos.y * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.which === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.which;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which !== 17) {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    if (event.altKey && event.which !== 18) {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    if (event.shiftKey && event.which !== 16) {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data']);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.one(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager) {\n",
       "        manager = IPython.keyboard_manager;\n",
       "    }\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"639.8333333333334\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "graph=dgl.DGLGraph(spp.coo_matrix(adj[1][:last_vis_obj[1],:last_vis_obj[1]]))\n",
    "nx.draw(graph.to_networkx(), with_labels=True)\n",
    "plt.subplot(1,2,2)\n",
    "graph=dgl.DGLGraph(spp.coo_matrix(adj[2][:last_vis_obj[2],:last_vis_obj[2]]))\n",
    "nx.draw(graph.to_networkx(), with_labels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREPROCESS DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear grafo (Ejemplo secuencia 0)\n",
    "Para el entrenamiento iterar sobre todas las secuencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "now_history_frame=6\n",
    "object_type = features[:,:,:,2].int()  # torch Tensor NxVxT\n",
    "#vis_obj_type=np.zeros((features.shape[0],features.shape[1])) #NxV\n",
    "mask_car=np.zeros((features.shape[0],features.shape[1],now_history_frame)) #NxVx6\n",
    "for i in range(len(features)):\n",
    "    #vis_obj_type[i,:] =object_type[i,:,5] #Append Vx1 #tipos de obj visibles de la primera seq    \n",
    "    mask_car_t=np.array([1  if (j==2 or j==1) else 0 for j in object_type[i,:,5]])  #1 si obj 1/2 en frame 5 (size V)\n",
    "    mask_car[i,:]=np.array(mask_car_t).reshape(mask_car.shape[1],1)+np.zeros(6) #Vx6 mask para los 6 output frames que indican si el obj es visible y car\n",
    "\n",
    "#COMPROBADO OK\n",
    "feature_id = [3, 4, 9]  #x,y,heading,[visible_mask]\n",
    "#120 agentes (13 visibles -> feat[11]=1) y 12 frames (si no hay info en alguno de os 12 frames: fila nula)\n",
    "node_features = features[:,:,:now_history_frame,feature_id]  #obj type,x,y 6 primeros frames\n",
    "node_labels=features[:,:,now_history_frame:,3:5] #x,y 6 ultimos frames\n",
    "node_features[:,:,:,-1] *= mask_car   #Pongo 0 en feat 11 [mask] a todos los obj visibles no-car\n",
    "print(node_labels.shape)\n",
    "node_labels[:,:,:,-1] *= mask_car\n",
    "output_mask= features[:,:,6:,-1]*mask_car #mascara obj (car) visibles en 6º frame (5010,120,6)\n",
    "output_mask.unsqueeze_(-1).type(torch.uint8)    #N,V,T,1                  \n",
    "\n",
    "print(node_features.shape, node_labels.shape,output_mask.shape)\n",
    "zero_indeces_list = [i for i in range(len(output_mask)) if np.all(np.array(output_mask.squeeze(-1))==0, axis=(1,2))[i] == True ]\n",
    "zero_maskcar_list = [i for i in range(len(mask_car)) if np.all(np.array(mask_car)==0, axis=(1,2))[i] == True ]\n",
    "#len(zero_maskcar_list) #374\n",
    "\n",
    "total_num = len(features)\n",
    "id_list = list(set(list(range(total_num))) - set(zero_indeces_list))\n",
    "total_valid_num = len(id_list) #4596\n",
    "ind=np.random.permutation(id_list)\n",
    "train_id_list, val_id_list = ind[:round(total_valid_num*0.8)], ind[round(total_valid_num*0.8):]\n",
    "\n",
    "print(len(train_id_list)) #3677\n",
    "xy_dist=[spatial.distance.cdist(node_features[i][:,5,:], node_features[i][:,5,:]) for i in range(len(features))]  #5010x120x120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl.function as fn\n",
    "#Perform message passing and then apply fc Layer (self-loops! - same W for neighbors and itself)\n",
    "# Traditional GCN:\n",
    "#fn.copy_src(src='h', out='m')\n",
    "#gcn_reduce = fn.sum(msg='m', out='h')\n",
    "# multiply source node features with edge weights and aggregate them in destination nodes\n",
    "gcn_msg=fn.u_mul_e('h', 'w', 'm') #elemnt-wise (broadcast)\n",
    "gcn_reduce = fn.sum(msg='m', out='h')\n",
    "class GCNLayer(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats, dropout):\n",
    "        super(GCNLayer, self).__init__()\n",
    "        self.linear_self = nn.Linear(in_feats, out_feats, bias=False)\n",
    "        self.linear = nn.Linear(in_feats, out_feats)\n",
    "        if dropout:\n",
    "            self.dropout = nn.Dropout(dropout)\n",
    "        else:\n",
    "            self.dropout = 0.\n",
    "        \n",
    "    def reduce_func(self, nodes):\n",
    "        h = torch.sum(nodes.mailbox['m'], dim=1)\n",
    "        return {'h': h}\n",
    "\n",
    "    def forward(self, g, feature,e_w, snorm_n, snorm_e):\n",
    "        # Creating a local scope so that all the stored ndata and edata\n",
    "        # (such as the `'h'` ndata below) are automatically popped out\n",
    "        # when the scope exits.\n",
    "        with g.local_scope():\n",
    "            \n",
    "            if self.dropout:\n",
    "                feature = self.dropout(feature)\n",
    "            \n",
    "            g.ndata['h_s']=self.linear_self(feature)\n",
    "            \n",
    "            #normalization\n",
    "            degs = g.out_degrees().float().clamp(min=1)\n",
    "            norm=torch.pow(degs,-0.5)\n",
    "            shp = norm.shape + (1,)*(feature.dim() -1)\n",
    "            norm = torch.reshape(norm,shp)\n",
    "            feature = feature*norm\n",
    "            \n",
    "            #aggregate\n",
    "            g.edata['w'] = e_w\n",
    "            g.ndata['h'] = feature\n",
    "            g.update_all(gcn_msg, self.reduce_func)\n",
    "            \n",
    "            #mult W and normalization\n",
    "            h = self.linear(g.ndata['h'])\n",
    "            degs = g.in_degrees().float().clamp(min=1)\n",
    "            norm = torch.pow(degs, -0.5)\n",
    "            shp = norm.shape + (1,) * (feature.dim() - 1)\n",
    "            norm = torch.reshape(norm, shp)\n",
    "            h = h * norm\n",
    "            \n",
    "            h = g.ndata['h_s'] + h #Vx6xout_feats\n",
    "            \n",
    "            #h = h * (torch.ones_like(h)*snorm_n)  # normalize activation w.r.t. graph node size\n",
    "            #e_w =  e_w * (torch.ones_like(e_w)*snorm_e)  # normalize activation w.r.t. graph edge size\n",
    "            e_w =  e_w\n",
    "            \n",
    "            return h, e_w\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, hid_feats, out_feats, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding_h = nn.Linear(in_feats, hid_feats)\n",
    "        self.conv1 = GCNLayer(in_feats=hid_feats, out_feats=hid_feats)\n",
    "        self.conv2 = GCNLayer(in_feats=hid_feats, out_feats=hid_feats)\n",
    "        self.fc= nn.Linear(hid_feats,out_feats)\n",
    "        self.dropout = dropout\n",
    "        if dropout:\n",
    "            self.linear_dropout = nn.Dropout(dropout)\n",
    "        else:\n",
    "            self.linear_dropout = 0.\n",
    "    def forward(self, graph, inputs,e_w,snorm_n, snorm_e):\n",
    "        # input embedding\n",
    "        h = self.embedding_h(inputs)\n",
    "        h,_ = self.conv1(graph, h,e_w,snorm_n, snorm_e,self.dropout) #Vx6x4 -> Vx6x32  \n",
    "        h = F.relu(h)\n",
    "        h,_ = self.conv2(graph,h,e_w,snorm_n, snorm_e,self.dropout)  #Vx6x2 \n",
    "        h = F.relu(h)\n",
    "        h = self.linear_dropout(h)\n",
    "        y = self.fc(h)\n",
    "        return y\n",
    "\n",
    "'''\n",
    "from dgl.nn import GatedGraphConv, GraphConv, GATConv,SAGEConv\n",
    "conv = GraphConv(4,2, weight=True, bias=True)\n",
    "#sageconv = SAGEConv(4,2,aggregator_type='lstm')\n",
    "#gated_conv = GatedGraphConv(4, 2, 2, 3)\n",
    "#gatconv=GATConv(4,2,num_heads=4)\n",
    "graph = dgl.add_self_loop(graph)   #Añado selfloops pq no puede haber zero in-degree nodes\n",
    "res = conv(graph, node_features[0])\n",
    "print(res.shape)\n",
    "'''    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My_GAT(\n",
      "  (embedding_h): Linear(in_features=24, out_features=128, bias=True)\n",
      "  (gat_1): My_GATLayer(\n",
      "    (linear_self): Linear(in_features=128, out_features=128, bias=False)\n",
      "    (linear_func): Linear(in_features=128, out_features=128, bias=False)\n",
      "    (attention_func): Linear(in_features=256, out_features=1, bias=False)\n",
      "    (feat_drop): Dropout(p=0.0, inplace=False)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (gat_2): My_GATLayer(\n",
      "    (linear_self): Linear(in_features=128, out_features=128, bias=False)\n",
      "    (linear_func): Linear(in_features=128, out_features=128, bias=False)\n",
      "    (attention_func): Linear(in_features=256, out_features=1, bias=False)\n",
      "    (feat_drop): Dropout(p=0.0, inplace=False)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (linear1): Linear(in_features=128, out_features=12, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class My_GATLayer(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats, feat_drop=0., attn_drop=0.):\n",
    "        super(My_GATLayer, self).__init__()\n",
    "        self.linear_self = nn.Linear(in_feats, out_feats, bias=False)\n",
    "        self.linear_func = nn.Linear(in_feats, out_feats, bias=False)\n",
    "        self.attention_func = nn.Linear(2 * out_feats, 1, bias=False)\n",
    "        self.feat_drop = nn.Dropout(feat_drop)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        #self.bn_node = nn.BatchNorm1d(out_feats)\n",
    "        \n",
    "        self.reset_parameters()\n",
    "    \n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        \"\"\"Reinitialize learnable parameters.\"\"\"\n",
    "        gain = nn.init.calculate_gain('relu')\n",
    "        nn.init.xavier_normal_(self.linear_self.weight, gain=gain)\n",
    "        nn.init.xavier_normal_(self.linear_func.weight, gain=gain)\n",
    "        nn.init.xavier_normal_(self.attention_func.weight, gain=gain)\n",
    "    \n",
    "    def edge_attention(self, edges):\n",
    "        concat_z = torch.cat([edges.src['z'], edges.dst['z']], dim=-1) #(n_edg,6*64)||(n_edg,6*64) -> (n_edg,2*6*64) \n",
    "        src_e = self.attention_func(concat_z)  #(n_edg, 1) att logit\n",
    "        src_e = F.leaky_relu(src_e)\n",
    "        return {'e': src_e}\n",
    "    \n",
    "    def message_func(self, edges):\n",
    "        return {'z': edges.src['z'], 'e':edges.data['e']}\n",
    "        \n",
    "    def reduce_func(self, nodes):\n",
    "        h_s = nodes.data['h_s']\n",
    "        \n",
    "        #ATTN DROPOUT\n",
    "        a = self.attn_drop(   F.softmax(nodes.mailbox['e'], dim=1)  )  #attention score between nodes i and j\n",
    "        \n",
    "        h = h_s + torch.sum(a * nodes.mailbox['z'], dim=1)\n",
    "        return {'h': h}\n",
    "                               \n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            \n",
    "            #feat dropout\n",
    "            h=self.feat_drop(h)\n",
    "            \n",
    "            h_in = h\n",
    "            g.ndata['h']  = h \n",
    "            g.ndata['h_s'] = self.linear_self(h) \n",
    "            g.ndata['z'] = self.linear_func(h) #(18) -> (18) \n",
    "            g.apply_edges(self.edge_attention)\n",
    "            g.update_all(self.message_func, self.reduce_func)\n",
    "            h = g.ndata['h'] # result of graph convolution\n",
    "            #h = h * snorm_n # normalize activation w.r.t. graph node size\n",
    "            #h = self.bn_node(h) # batch normalization \n",
    "            \n",
    "            h = torch.relu(h) # non-linear activation\n",
    "            h = h_in + h # residual connection\n",
    "            \n",
    "            return h #graph.ndata.pop('h')\n",
    "\n",
    "\n",
    "class MultiHeadGATLayer(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats, num_heads, merge='cat'):\n",
    "        super(MultiHeadGATLayer, self).__init__()\n",
    "        self.heads = nn.ModuleList()\n",
    "        for i in range(num_heads):\n",
    "            self.heads.append(My_GATLayer(in_feats, out_feats))\n",
    "        self.merge = merge\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        head_outs = [attn_head(g, h) for attn_head in self.heads]\n",
    "        if self.merge == 'cat':\n",
    "            # concat on the output feature dimension (dim=1), for intermediate layers\n",
    "            return torch.cat(head_outs, dim=1)\n",
    "        else:\n",
    "            # merge using average, for final layer\n",
    "            return torch.mean(torch.stack(head_outs))\n",
    "\n",
    "class MLP_layer(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, input_dim/2) \n",
    "        self.layer2 = nn.Linear(input_dim/2, input_dim/4) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = x\n",
    "        y = self.layer1(y)\n",
    "        y = torch.relu(y)\n",
    "        y = self.layer2(y)\n",
    "        return y\n",
    "    \n",
    "    \n",
    "class My_GAT(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, dropout, feat_drop=0., attn_drop=0., heads=4):\n",
    "        super().__init__()\n",
    "        self.embedding_h = nn.Linear(input_dim, hidden_dim)\n",
    "        self.gat_1 = My_GATLayer(hidden_dim, hidden_dim, feat_drop, attn_drop)\n",
    "        self.gat_2 = My_GATLayer(hidden_dim, hidden_dim, feat_drop, attn_drop)\n",
    "        #self.gat_1 = MultiHeadGATLayer(hidden_dim, hidden_dim, heads)\n",
    "        #self.gat_2 = MultiHeadGATLayer(hidden_dim*heads, hidden_dim*heads, 1)\n",
    "        \n",
    "        self.linear1 = nn.Linear(hidden_dim, output_dim) #hidden*heads para multihead\n",
    "        #self.linear2 = nn.Linear( int(hidden_dim/2),  output_dim)\n",
    "        \n",
    "        if dropout:\n",
    "            self.dropout = nn.Dropout(dropout)\n",
    "        else:\n",
    "            self.dropout = 0.\n",
    "        \n",
    "    def forward(self, g, h,e_w,snorm_n,snorm_e):\n",
    "        \n",
    "        # input embedding\n",
    "        h = self.embedding_h(h)  #input (70, 6,4) - (70, 6,32) checked\n",
    "        # gat layers\n",
    "        h = self.gat_1(g, h)\n",
    "        h = self.gat_2(g, h)\n",
    "        \n",
    "        h = self.dropout(h)\n",
    "        y = self.linear1(h) \n",
    "        #y = self.linear2(torch.relu(y))\n",
    "        return y\n",
    "    \n",
    "print( My_GAT(input_dim=24, hidden_dim=128, output_dim=12, dropout=0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gated GCN \n",
    "$$\n",
    "\\def \\vx {\\boldsymbol{\\color{Plum}{x}}}\n",
    "\\def \\vh {\\boldsymbol{\\color{YellowGreen}{h}}}\n",
    "\\def \\ve {\\boldsymbol{\\color{purple}{e}}}\n",
    "\\def \\aqua#1{\\color{Aquamarine}{#1}}\n",
    "\\def \\red#1{\\color{OrangeRed}{#1}}\n",
    "$$\n",
    "\n",
    "\\begin{aligned}\n",
    "\\vh &= \\vx + \\Big( A \\vx +  \\sum_{\\aqua{v}_j \\to \\red{v}} \\eta(\\ve_{j}) \\odot B \\vx_j \\Big)^+\\\\\n",
    "\\eta(\\ve_{j}) &= \\sigma(\\ve_{j})\\Big(\\sum_{\\aqua{v}_k \\to \\red{v}} \\sigma(\\ve_{k})\\Big)^{-1} \\\\\n",
    "\\ve_{j} &= C \\ve_{j}^{\\vx} + D \\vx_j + E\\vx\\\\\n",
    "\\ve_{j}^{\\vh} &= \\ve_j^{\\vx} + \\Big( \\ve_{j}  \\Big)^+\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatedGCN_layer(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.A = nn.Linear(input_dim, output_dim)\n",
    "        self.B = nn.Linear(input_dim, output_dim)\n",
    "        self.C = nn.Linear(input_dim, output_dim)\n",
    "        self.D = nn.Linear(input_dim, output_dim)\n",
    "        self.E = nn.Linear(input_dim, output_dim)\n",
    "        self.bn_node_h = nn.BatchNorm1d(output_dim)\n",
    "        self.bn_node_e = nn.BatchNorm1d(output_dim)\n",
    "\n",
    "    def message_func(self, edges):\n",
    "        Bh_j = edges.src['Bh']\n",
    "        # e_ij = Ce_ij + Dhi + Ehj   N*B,256\n",
    "        e_ij = edges.data['Ce'] + edges.src['Dh'] + edges.dst['Eh']\n",
    "        edges.data['e'] = e_ij\n",
    "        return {'Bh_j' : Bh_j, 'e_ij' : e_ij}\n",
    "\n",
    "    def reduce_func(self, nodes):\n",
    "        Ah_i = nodes.data['Ah']\n",
    "        Bh_j = nodes.mailbox['Bh_j']\n",
    "        e = nodes.mailbox['e_ij']\n",
    "        # sigma_ij = sigmoid(e_ij)\n",
    "        \n",
    "        torch.clamp(e.sigmoid_(), min=1e-4, max=1-1e-4) \n",
    "        sigma_ij = torch.sigmoid(e)\n",
    "        # hi = Ahi + sum_j eta_ij * Bhj   \n",
    "        h = Ah_i + torch.sum(sigma_ij * Bh_j, dim=1) / torch.sum(sigma_ij, dim=1)  #shape n_nodes*256\n",
    "        return {'h' : h}\n",
    "    \n",
    "    def forward(self, g, h, e, snorm_n, snorm_e):\n",
    "        \n",
    "        h_in = h # residual connection\n",
    "        e_in = e # residual connection\n",
    "        \n",
    "        \n",
    "        g.ndata['h']  = h \n",
    "        g.ndata['Ah'] = self.A(h) \n",
    "        g.ndata['Bh'] = self.B(h) \n",
    "        g.ndata['Dh'] = self.D(h)\n",
    "        g.ndata['Eh'] = self.E(h) \n",
    "        g.edata['e']  = e \n",
    "        g.edata['Ce'] = self.C(e)\n",
    "        \n",
    "        g.update_all(self.message_func, self.reduce_func)\n",
    "        \n",
    "        h = g.ndata['h'] # result of graph convolution\n",
    "        e = g.edata['e'] # result of graph convolution\n",
    "\n",
    "        \n",
    "        h = h * snorm_n # normalize activation w.r.t. graph node size\n",
    "        e = e * snorm_e # normalize activation w.r.t. graph edge size\n",
    "        \n",
    "        h = self.bn_node_h(h) # batch normalization  \n",
    "        e = self.bn_node_e(e) # batch normalization  \n",
    "        \n",
    "        h = torch.relu(h) # non-linear activation\n",
    "        e = torch.relu(e) # non-linear activation\n",
    "        \n",
    "        h = h_in + h # residual connection\n",
    "        e = e_in + e # residual connection\n",
    "        \n",
    "        return h, e\n",
    "    \n",
    "class GatedGCN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.embedding_h = nn.Linear(input_dim, hidden_dim)\n",
    "        self.embedding_e = nn.Linear(1, hidden_dim)\n",
    "        self.GatedGCN1 = GatedGCN_layer(hidden_dim, hidden_dim)\n",
    "        self.GatedGCN2 = GatedGCN_layer(hidden_dim, hidden_dim)\n",
    "        self.linear1 = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, g, h, e, snorm_n, snorm_e):\n",
    "        # input embedding\n",
    "        h = self.embedding_h(h)\n",
    "        e = self.embedding_e(e)\n",
    "        # graph convnet layers\n",
    "        h, e = self.GatedGCN1(g, h, e, snorm_n, snorm_e)\n",
    "        h, e = self.GatedGCN2(g, h, e, snorm_n, snorm_e)\n",
    "        # MLP \n",
    "        y = self.linear1(h)\n",
    "        \n",
    "        return y\n",
    "\n",
    "print( GatedGCN(input_dim=18, hidden_dim=64, output_dim=12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Lightning Sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: voe9e855\n",
      "Sweep URL: https://wandb.ai/sandracl72/dbu_graph/sweeps/voe9e855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: g4tnh6lx with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dims: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_type: gcn\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msandracl72\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.11<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">misty-sweep-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/sandracl72/dbu_graph\" target=\"_blank\">https://wandb.ai/sandracl72/dbu_graph</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/sandracl72/dbu_graph/sweeps/voe9e855\" target=\"_blank\">https://wandb.ai/sandracl72/dbu_graph/sweeps/voe9e855</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/sandracl72/dbu_graph/runs/g4tnh6lx\" target=\"_blank\">https://wandb.ai/sandracl72/dbu_graph/runs/g4tnh6lx</a><br/>\n",
       "                Run data is saved locally in <code>/home/sandra/PROGRAMAS/DBU_Graph/wandb/run-20201119_155330-g4tnh6lx</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcn\n",
      "############### TRAIN ####################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:g4tnh6lx) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 9070<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d3be7cad15e42b897445a73d0eaaed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=0.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/sandra/PROGRAMAS/DBU_Graph/wandb/run-20201119_155330-g4tnh6lx/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/sandra/PROGRAMAS/DBU_Graph/wandb/run-20201119_155330-g4tnh6lx/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">misty-sweep-1</strong>: <a href=\"https://wandb.ai/sandracl72/dbu_graph/runs/g4tnh6lx\" target=\"_blank\">https://wandb.ai/sandracl72/dbu_graph/runs/g4tnh6lx</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:g4tnh6lx). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.11<br/>\n",
       "                Resuming run <strong style=\"color:#cdcd00\">misty-sweep-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/sandracl72/dbu_graph\" target=\"_blank\">https://wandb.ai/sandracl72/dbu_graph</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/sandracl72/dbu_graph/sweeps/voe9e855\" target=\"_blank\">https://wandb.ai/sandracl72/dbu_graph/sweeps/voe9e855</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/sandracl72/dbu_graph/runs/g4tnh6lx\" target=\"_blank\">https://wandb.ai/sandracl72/dbu_graph/runs/g4tnh6lx</a><br/>\n",
       "                Run data is saved locally in <code>./logs/wandb/run-20201119_155331-g4tnh6lx</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | GCN  | 18 K  \n",
      "/home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69df7064449b48ac85d329c101904096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validation sanity check'), FloatProgress(value=1.0, bar_style='info', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1501983bc9af42f6b7c6bc81b4e3696d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 9098<br/>Program failed with code 1.  Press ctrl-c to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e659a37a5d84621b4c20b785688fa29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>./logs/wandb/run-20201119_155331-g4tnh6lx/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>./logs/wandb/run-20201119_155331-g4tnh6lx/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>val/Loss</td><td>174.94234</td></tr><tr><td>_step</td><td>0</td></tr><tr><td>_runtime</td><td>4</td></tr><tr><td>_timestamp</td><td>1605797617</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>val/Loss</td><td>▁</td></tr><tr><td>_step</td><td>▁</td></tr><tr><td>_runtime</td><td>▁</td></tr><tr><td>_timestamp</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">misty-sweep-1</strong>: <a href=\"https://wandb.ai/sandracl72/dbu_graph/runs/g4tnh6lx\" target=\"_blank\">https://wandb.ai/sandracl72/dbu_graph/runs/g4tnh6lx</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run g4tnh6lx errored: DGLError('Caught DGLError in DataLoader worker process 0.\\nOriginal Traceback (most recent call last):\\n  File \"/home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 198, in _worker_loop\\n    data = fetcher.fetch(index)\\n  File \"/home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\\n    return self.collate_fn(data)\\n  File \"<ipython-input-2-937fb2f09b21>\", line 15, in collate_batch\\n    return batched_graph.to(dev), masks.to(dev), snorm_n.to(dev), snorm_e.to(dev)\\n  File \"/home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/dgl/heterograph.py\", line 5005, in to\\n    ret._graph = self._graph.copy_to(utils.to_dgl_context(device))\\n  File \"/home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/dgl/heterograph_index.py\", line 234, in copy_to\\n    return _CAPI_DGLHeteroCopyTo(self, ctx.device_type, ctx.device_id)\\n  File \"dgl/_ffi/_cython/./function.pxi\", line 287, in dgl._ffi._cy3.core.FunctionBase.__call__\\n  File \"dgl/_ffi/_cython/./function.pxi\", line 222, in dgl._ffi._cy3.core.FuncCall\\n  File \"dgl/_ffi/_cython/./function.pxi\", line 211, in dgl._ffi._cy3.core.FuncCall3\\n  File \"dgl/_ffi/_cython/./base.pxi\", line 155, in dgl._ffi._cy3.core.CALL\\ndgl._ffi.base.DGLError: [15:53:37] /opt/dgl/src/runtime/cuda/cuda_device_api.cc:93: Check failed: e == cudaSuccess || e == cudaErrorCudartUnloading: CUDA: initialization error\\nStack trace:\\n  [bt] (0) /home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/dgl/libdgl.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x4f) [0x7fec2ff768af]\\n  [bt] (1) /home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/dgl/libdgl.so(dgl::runtime::CUDADeviceAPI::AllocDataSpace(DLContext, unsigned long, unsigned long, DLDataType)+0x283) [0x7fec30768e53]\\n  [bt] (2) /home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/dgl/libdgl.so(dgl::runtime::NDArray::Empty(std::vector<long, std::allocator<long> >, DLDataType, DLContext)+0x177) [0x7fec30627d47]\\n  [bt] (3) /home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/dgl/libdgl.so(dgl::runtime::NDArray::CopyTo(DLContext const&) const+0xc0) [0x7fec3065cc10]\\n  [bt] (4) /home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/dgl/libdgl.so(dgl::UnitGraph::CopyTo(std::shared_ptr<dgl::BaseHeteroGraph>, DLContext const&)+0x2eb) [0x7fec3073c00b]\\n  [bt] (5) /home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/dgl/libdgl.so(dgl::HeteroGraph::CopyTo(std::shared_ptr<dgl::BaseHeteroGraph>, DLContext const&)+0xf5) [0x7fec3066df25]\\n  [bt] (6) /home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/dgl/libdgl.so(+0xecdfbb) [0x7fec3067afbb]\\n  [bt] (7) /home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/dgl/libdgl.so(DGLFuncCall+0x48) [0x7fec3060bde8]\\n  [bt] (8) /home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/dgl/_ffi/_cy3/core.cpython-38-x86_64-linux-gnu.so(+0x16f99) [0x7fec2e001f99]\\n\\n\\n')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run g4tnh6lx errored: DGLError('Caught DGLError in DataLoader worker process 0.\\nOriginal Traceback (most recent call last):\\n  File \"/home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 198, in _worker_loop\\n    data = fetcher.fetch(index)\\n  File \"/home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\\n    return self.collate_fn(data)\\n  File \"<ipython-input-2-937fb2f09b21>\", line 15, in collate_batch\\n    return batched_graph.to(dev), masks.to(dev), snorm_n.to(dev), snorm_e.to(dev)\\n  File \"/home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/dgl/heterograph.py\", line 5005, in to\\n    ret._graph = self._graph.copy_to(utils.to_dgl_context(device))\\n  File \"/home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/dgl/heterograph_index.py\", line 234, in copy_to\\n    return _CAPI_DGLHeteroCopyTo(self, ctx.device_type, ctx.device_id)\\n  File \"dgl/_ffi/_cython/./function.pxi\", line 287, in dgl._ffi._cy3.core.FunctionBase.__call__\\n  File \"dgl/_ffi/_cython/./function.pxi\", line 222, in dgl._ffi._cy3.core.FuncCall\\n  File \"dgl/_ffi/_cython/./function.pxi\", line 211, in dgl._ffi._cy3.core.FuncCall3\\n  File \"dgl/_ffi/_cython/./base.pxi\", line 155, in dgl._ffi._cy3.core.CALL\\ndgl._ffi.base.DGLError: [15:53:37] /opt/dgl/src/runtime/cuda/cuda_device_api.cc:93: Check failed: e == cudaSuccess || e == cudaErrorCudartUnloading: CUDA: initialization error\\nStack trace:\\n  [bt] (0) /home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/dgl/libdgl.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x4f) [0x7fec2ff768af]\\n  [bt] (1) /home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/dgl/libdgl.so(dgl::runtime::CUDADeviceAPI::AllocDataSpace(DLContext, unsigned long, unsigned long, DLDataType)+0x283) [0x7fec30768e53]\\n  [bt] (2) /home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/dgl/libdgl.so(dgl::runtime::NDArray::Empty(std::vector<long, std::allocator<long> >, DLDataType, DLContext)+0x177) [0x7fec30627d47]\\n  [bt] (3) /home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/dgl/libdgl.so(dgl::runtime::NDArray::CopyTo(DLContext const&) const+0xc0) [0x7fec3065cc10]\\n  [bt] (4) /home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/dgl/libdgl.so(dgl::UnitGraph::CopyTo(std::shared_ptr<dgl::BaseHeteroGraph>, DLContext const&)+0x2eb) [0x7fec3073c00b]\\n  [bt] (5) /home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/dgl/libdgl.so(dgl::HeteroGraph::CopyTo(std::shared_ptr<dgl::BaseHeteroGraph>, DLContext const&)+0xf5) [0x7fec3066df25]\\n  [bt] (6) /home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/dgl/libdgl.so(+0xecdfbb) [0x7fec3067afbb]\\n  [bt] (7) /home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/dgl/libdgl.so(DGLFuncCall+0x48) [0x7fec3060bde8]\\n  [bt] (8) /home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/dgl/_ffi/_cy3/core.cpython-38-x86_64-linux-gnu.so(+0x16f99) [0x7fec2e001f99]\\n\\n\\n')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3pobvosn with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dims: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_type: gat\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.11<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">vivid-sweep-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/sandracl72/dbu_graph\" target=\"_blank\">https://wandb.ai/sandracl72/dbu_graph</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/sandracl72/dbu_graph/sweeps/voe9e855\" target=\"_blank\">https://wandb.ai/sandracl72/dbu_graph/sweeps/voe9e855</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/sandracl72/dbu_graph/runs/3pobvosn\" target=\"_blank\">https://wandb.ai/sandracl72/dbu_graph/runs/3pobvosn</a><br/>\n",
       "                Run data is saved locally in <code>/home/sandra/PROGRAMAS/DBU_Graph/wandb/run-20201119_155341-3pobvosn</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gat\n",
      "############### TRAIN ####################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3pobvosn) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 9170<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aae1a241adf48c8af3cbf533beb3dc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=0.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/sandra/PROGRAMAS/DBU_Graph/wandb/run-20201119_155341-3pobvosn/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/sandra/PROGRAMAS/DBU_Graph/wandb/run-20201119_155341-3pobvosn/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">vivid-sweep-2</strong>: <a href=\"https://wandb.ai/sandracl72/dbu_graph/runs/3pobvosn\" target=\"_blank\">https://wandb.ai/sandracl72/dbu_graph/runs/3pobvosn</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:3pobvosn). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.11<br/>\n",
       "                Resuming run <strong style=\"color:#cdcd00\">vivid-sweep-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/sandracl72/dbu_graph\" target=\"_blank\">https://wandb.ai/sandracl72/dbu_graph</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/sandracl72/dbu_graph/sweeps/voe9e855\" target=\"_blank\">https://wandb.ai/sandracl72/dbu_graph/sweeps/voe9e855</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/sandracl72/dbu_graph/runs/3pobvosn\" target=\"_blank\">https://wandb.ai/sandracl72/dbu_graph/runs/3pobvosn</a><br/>\n",
       "                Run data is saved locally in <code>./logs/wandb/run-20201119_155342-3pobvosn</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type   | Params\n",
      "---------------------------------\n",
      "0 | model | My_GAT | 18 K  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "005565b2018c47499b304b54cc344153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validation sanity check'), FloatProgress(value=1.0, bar_style='info', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21567f9e77cc4f6cbacf542c56c9212b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 9198<br/>Program failed with code 1.  Press ctrl-c to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "511bf40728cf418b932ecb3d474bba80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>./logs/wandb/run-20201119_155342-3pobvosn/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>./logs/wandb/run-20201119_155342-3pobvosn/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>val/Loss</td><td>189.18094</td></tr><tr><td>_step</td><td>0</td></tr><tr><td>_runtime</td><td>4</td></tr><tr><td>_timestamp</td><td>1605797628</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>val/Loss</td><td>▁</td></tr><tr><td>_step</td><td>▁</td></tr><tr><td>_runtime</td><td>▁</td></tr><tr><td>_timestamp</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">vivid-sweep-2</strong>: <a href=\"https://wandb.ai/sandracl72/dbu_graph/runs/3pobvosn\" target=\"_blank\">https://wandb.ai/sandracl72/dbu_graph/runs/3pobvosn</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run 3pobvosn errored: DGLError('Caught DGLError in DataLoader worker process 0.\\nOriginal Traceback (most recent call last):\\n  File \"/home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 198, in _worker_loop\\n    data = fetcher.fetch(index)\\n  File \"/home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\\n    return self.collate_fn(data)\\n  File \"<ipython-input-2-937fb2f09b21>\", line 15, in collate_batch\\n    return batched_graph.to(dev), masks.to(dev), snorm_n.to(dev), snorm_e.to(dev)\\n  File \"/home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/dgl/heterograph.py\", line 5005, in to\\n    ret._graph = self._graph.copy_to(utils.to_dgl_context(device))\\n  File \"/home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/dgl/heterograph_index.py\", line 234, in copy_to\\n    return _CAPI_DGLHeteroCopyTo(self, ctx.device_type, ctx.device_id)\\n  File \"dgl/_ffi/_cython/./function.pxi\", line 287, in dgl._ffi._cy3.core.FunctionBase.__call__\\n  File \"dgl/_ffi/_cython/./function.pxi\", line 222, in dgl._ffi._cy3.core.FuncCall\\n  File \"dgl/_ffi/_cython/./function.pxi\", line 211, in dgl._ffi._cy3.core.FuncCall3\\n  File \"dgl/_ffi/_cython/./base.pxi\", line 155, in dgl._ffi._cy3.core.CALL\\ndgl._ffi.base.DGLError: [15:53:48] /opt/dgl/src/runtime/cuda/cuda_device_api.cc:93: Check failed: e == cudaSuccess || e == cudaErrorCudartUnloading: CUDA: initialization error\\nStack trace:\\n  [bt] (0) /home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/dgl/libdgl.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x4f) [0x7fec2ff768af]\\n  [bt] (1) /home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/dgl/libdgl.so(dgl::runtime::CUDADeviceAPI::AllocDataSpace(DLContext, unsigned long, unsigned long, DLDataType)+0x283) [0x7fec30768e53]\\n  [bt] (2) /home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/dgl/libdgl.so(dgl::runtime::NDArray::Empty(std::vector<long, std::allocator<long> >, DLDataType, DLContext)+0x177) [0x7fec30627d47]\\n  [bt] (3) /home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/dgl/libdgl.so(dgl::runtime::NDArray::CopyTo(DLContext const&) const+0xc0) [0x7fec3065cc10]\\n  [bt] (4) /home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/dgl/libdgl.so(dgl::UnitGraph::CopyTo(std::shared_ptr<dgl::BaseHeteroGraph>, DLContext const&)+0x2eb) [0x7fec3073c00b]\\n  [bt] (5) /home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/dgl/libdgl.so(dgl::HeteroGraph::CopyTo(std::shared_ptr<dgl::BaseHeteroGraph>, DLContext const&)+0xf5) [0x7fec3066df25]\\n  [bt] (6) /home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/dgl/libdgl.so(+0xecdfbb) [0x7fec3067afbb]\\n  [bt] (7) /home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/dgl/libdgl.so(DGLFuncCall+0x48) [0x7fec3060bde8]\\n  [bt] (8) /home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/dgl/_ffi/_cy3/core.cpython-38-x86_64-linux-gnu.so(+0x16f99) [0x7fec2e001f99]\\n\\n\\n')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 3pobvosn errored: DGLError('Caught DGLError in DataLoader worker process 0.\\nOriginal Traceback (most recent call last):\\n  File \"/home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 198, in _worker_loop\\n    data = fetcher.fetch(index)\\n  File \"/home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\\n    return self.collate_fn(data)\\n  File \"<ipython-input-2-937fb2f09b21>\", line 15, in collate_batch\\n    return batched_graph.to(dev), masks.to(dev), snorm_n.to(dev), snorm_e.to(dev)\\n  File \"/home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/dgl/heterograph.py\", line 5005, in to\\n    ret._graph = self._graph.copy_to(utils.to_dgl_context(device))\\n  File \"/home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/dgl/heterograph_index.py\", line 234, in copy_to\\n    return _CAPI_DGLHeteroCopyTo(self, ctx.device_type, ctx.device_id)\\n  File \"dgl/_ffi/_cython/./function.pxi\", line 287, in dgl._ffi._cy3.core.FunctionBase.__call__\\n  File \"dgl/_ffi/_cython/./function.pxi\", line 222, in dgl._ffi._cy3.core.FuncCall\\n  File \"dgl/_ffi/_cython/./function.pxi\", line 211, in dgl._ffi._cy3.core.FuncCall3\\n  File \"dgl/_ffi/_cython/./base.pxi\", line 155, in dgl._ffi._cy3.core.CALL\\ndgl._ffi.base.DGLError: [15:53:48] /opt/dgl/src/runtime/cuda/cuda_device_api.cc:93: Check failed: e == cudaSuccess || e == cudaErrorCudartUnloading: CUDA: initialization error\\nStack trace:\\n  [bt] (0) /home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/dgl/libdgl.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x4f) [0x7fec2ff768af]\\n  [bt] (1) /home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/dgl/libdgl.so(dgl::runtime::CUDADeviceAPI::AllocDataSpace(DLContext, unsigned long, unsigned long, DLDataType)+0x283) [0x7fec30768e53]\\n  [bt] (2) /home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/dgl/libdgl.so(dgl::runtime::NDArray::Empty(std::vector<long, std::allocator<long> >, DLDataType, DLContext)+0x177) [0x7fec30627d47]\\n  [bt] (3) /home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/dgl/libdgl.so(dgl::runtime::NDArray::CopyTo(DLContext const&) const+0xc0) [0x7fec3065cc10]\\n  [bt] (4) /home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/dgl/libdgl.so(dgl::UnitGraph::CopyTo(std::shared_ptr<dgl::BaseHeteroGraph>, DLContext const&)+0x2eb) [0x7fec3073c00b]\\n  [bt] (5) /home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/dgl/libdgl.so(dgl::HeteroGraph::CopyTo(std::shared_ptr<dgl::BaseHeteroGraph>, DLContext const&)+0xf5) [0x7fec3066df25]\\n  [bt] (6) /home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/dgl/libdgl.so(+0xecdfbb) [0x7fec3067afbb]\\n  [bt] (7) /home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/dgl/libdgl.so(DGLFuncCall+0x48) [0x7fec3060bde8]\\n  [bt] (8) /home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/dgl/_ffi/_cy3/core.cpython-38-x86_64-linux-gnu.so(+0x16f99) [0x7fec2e001f99]\\n\\n\\n')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qv9h5upm with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dims: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_type: gated\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.11<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">astral-sweep-3</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/sandracl72/dbu_graph\" target=\"_blank\">https://wandb.ai/sandracl72/dbu_graph</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/sandracl72/dbu_graph/sweeps/voe9e855\" target=\"_blank\">https://wandb.ai/sandracl72/dbu_graph/sweeps/voe9e855</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/sandracl72/dbu_graph/runs/qv9h5upm\" target=\"_blank\">https://wandb.ai/sandracl72/dbu_graph/runs/qv9h5upm</a><br/>\n",
       "                Run data is saved locally in <code>/home/sandra/PROGRAMAS/DBU_Graph/wandb/run-20201119_155352-qv9h5upm</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gated\n",
      "############### TRAIN ####################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:qv9h5upm) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 9264<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72701e22922244678b046d7eac07b952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=0.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "\n",
    "class LitGNN(pl.LightningModule):\n",
    "    def __init__(self, model: nn.Module = GCN, lr: float = 1e-3, batch_size: int = 64, model_type: str = 'gcn'):\n",
    "        super().__init__()\n",
    "        self.model= model\n",
    "        self.lr = lr\n",
    "        self.model_type = model_type\n",
    "        self.batch_size = batch_size\n",
    "        self.epoch=0\n",
    "        \n",
    "        self.overall_loss_train=[]\n",
    "        \n",
    "        self.overall_num_list=[]\n",
    "        self.overall_x2y2_list=[]\n",
    "        \n",
    "        self.test_overall_num_list=[]\n",
    "        self.test_overall_x2y2_list=[]\n",
    "        \n",
    "        wandb.watch(self.model, log=\"all\")\n",
    "        \n",
    "    \n",
    "    def forward(self, graph, feats,e_w,snorm_n,snorm_e):\n",
    "        pred = self.model(graph, feats,e_w,snorm_n,snorm_e)   #inference\n",
    "        return pred\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        opt = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return opt\n",
    "    \n",
    "    def compute_RMSE_batch(self,pred, gt, mask): \n",
    "        pred=pred.view(pred.shape[0],mask.shape[1],-1)\n",
    "        pred = pred*mask #B*V,T,C  (B n grafos en el batch)\n",
    "        gt = gt*mask  # outputmask BV,T,C\n",
    "        x2y2_error=torch.sum(torch.abs(pred-gt)**2,dim=-1) # x^2+y^2 BV,T\n",
    "        overall_sum_time = x2y2_error.sum(dim=-2)  #T - suma de los errores (x^2+y^2) de los V agentes\n",
    "        overall_num = mask.sum(dim=-1).type(torch.int)  #torch.Tensor[(T)] - num de agentes (Y CON DATOS) en cada frame\n",
    "        return overall_sum_time, overall_num, x2y2_error\n",
    "\n",
    "    \n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        batched_graph, output_masks,snorm_n, snorm_e = train_batch\n",
    "        feats = batched_graph.ndata['x'].float()\n",
    "        #reshape to have shape (B*V,T*C) [c1,c2,...,c6]\n",
    "        feats = feats.view(feats.shape[0],-1)\n",
    "        e_w = batched_graph.edata['w'].float()\n",
    "        if self.model_type == 'gated':\n",
    "            e_w= e_w.view(e_w.shape[0],1)\n",
    "        labels= batched_graph.ndata['gt'].float()\n",
    "        pred = self.model(batched_graph, feats,e_w,snorm_n,snorm_e)\n",
    "        overall_sum_time, overall_num, _ = self.compute_RMSE_batch(pred, labels, output_masks)  #(B,6)\n",
    "        total_loss=torch.sum(overall_sum_time)/torch.sum(overall_num.sum(dim=-2))\n",
    "        self.overall_loss_train.extend([total_loss.data.item()])\n",
    "        #self.log('train_loss',total_loss, prog_bar=True, logger=True, on_epoch=True)\n",
    "        return total_loss\n",
    "    \n",
    "    def training_epoch_end(self, total_loss):\n",
    "        self.epoch += 1\n",
    "        print('|{}| Train_loss: {}'.format(datetime.now(), np.sum(self.overall_loss_train)/len(self.overall_loss_train)))\n",
    "        #self.log(\"Train/Loss\", np.sum(self.overall_loss_train)/len(self.overall_loss_train) )\n",
    "        self.logger.log_metrics({\"Train/loss\": np.sum(self.overall_loss_train)/len(self.overall_loss_train)}, step=self.epoch)\n",
    "        #wandb.log({\"Train/loss\": np.sum(self.overall_loss_train)/len(self.overall_loss_train)}, step=self.epoch)#, step=epoch)      \n",
    "        self.overall_loss_train=[]\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        batched_graph, output_masks,snorm_n, snorm_e = val_batch\n",
    "        feats = batched_graph.ndata['x'].float()\n",
    "        #reshape to have shape (B*V,T*C) [c1,c2,...,c6]\n",
    "        feats = feats.view(feats.shape[0],-1)\n",
    "        e_w = batched_graph.edata['w'].float()\n",
    "        if self.model_type == 'gated':\n",
    "            e_w= e_w.view(e_w.shape[0],1)\n",
    "        labels= batched_graph.ndata['gt'].float()\n",
    "        pred = self.model(batched_graph, feats,e_w,snorm_n,snorm_e)\n",
    "        _, overall_num, x2y2_error = self.compute_RMSE_batch(pred, labels, output_masks)\n",
    "        self.overall_num_list.extend(overall_num.detach().cpu().numpy())\n",
    "        self.overall_x2y2_list.extend((x2y2_error**0.5).detach().cpu().numpy())  \n",
    "        \n",
    "    def validation_epoch_end(self, val_results):\n",
    "        overall_sum_time=np.sum(self.overall_x2y2_list,axis=0)  #BV,T->T RMSE medio en cada T\n",
    "        overall_num_time =np.sum(self.overall_num_list, axis=0)\n",
    "        overall_loss_time=(overall_sum_time / overall_num_time) #media del error de cada agente en cada frame\n",
    "        \n",
    "        self.overall_num_list=[]\n",
    "        self.overall_x2y2_list=[]\n",
    "        #self.log('val/Loss',np.sum(overall_loss_time), on_step=)\n",
    "        self.logger.log_metrics({'val/Loss':np.sum(overall_loss_time)}, step= self.epoch)\n",
    "        #wandb.log({\"Val/Loss\": np.sum(overall_loss_time)}, step= self.epoch)\n",
    "    \n",
    "    def test_step(self, test_batch, batch_idx):\n",
    "        batched_graph, output_masks,snorm_n, snorm_e = test_batch\n",
    "        feats = batched_graph.ndata['x'].float()\n",
    "        #reshape to have shape (B*V,T*C) [c1,c2,...,c6]\n",
    "        feats = feats.view(feats.shape[0],-1)\n",
    "        e_w = batched_graph.edata['w'].float()\n",
    "        if self.model_type == 'gated':\n",
    "            e_w= e_w.view(e_w.shape[0],1)\n",
    "        labels= batched_graph.ndata['gt'].float()\n",
    "        pred = self.model(batched_graph, feats,e_w,snorm_n,snorm_e)\n",
    "        _, overall_num, x2y2_error = self.compute_RMSE_batch(pred, labels, output_masks)\n",
    "        self.test_overall_num_list.extend(overall_num.detach().cpu().numpy())\n",
    "        self.test_overall_x2y2_list.extend((x2y2_error**0.5).detach().cpu().numpy())\n",
    "                  \n",
    "    def test_epoch_end(self,test_results):\n",
    "        overall_sum_time=np.sum(self.test_overall_x2y2_list,axis=0)  #BV,T->T RMSE medio en cada T\n",
    "        overall_num_time =np.sum(self.test_overall_num_list, axis=0)\n",
    "        overall_loss_time=(overall_sum_time / overall_num_time)\n",
    "        self.log('test/loss', np.sum(overall_loss_time))\n",
    "        #self.log('test/loss_per_sec',' '.join(['{:.3f}'.format(x) for x in list(overall_loss_time)]))\n",
    "        self.log('test/loss_per_sec', overall_loss_time)    \n",
    "\n",
    "        #wandb.log({'test/loss': np.sum(overall_loss_time)})    \n",
    "\n",
    "\n",
    "def sweep_train():\n",
    "\n",
    "    hyperparameters_default = dict (\n",
    "        batch_size = batch_size,\n",
    "        learning_rate = learning_rate,\n",
    "        hidden_dims = hidden_dims,\n",
    "        model_type = model_type,\n",
    "        epochs = total_epoch\n",
    "    )\n",
    "\n",
    "    wandb.init(config= hyperparameters_default) \n",
    "    config = wandb.config\n",
    "    wandb_logger = pl_loggers.WandbLogger(save_dir='./logs/')  #name=\n",
    "    train_dataloader=DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=12, collate_fn=collate_batch)\n",
    "\n",
    "    print(config.model_type)\n",
    "    if config.model_type == 'gat':\n",
    "        model = My_GAT(input_dim=18, hidden_dim=config.hidden_dims, output_dim=12)\n",
    "    elif config.model_type == 'gcn':\n",
    "        model = GCN(in_feats=18, hid_feats=config.hidden_dims, out_feats=12)\n",
    "    elif config.model_type == 'gated':\n",
    "        model = GatedGCN(input_dim=18, hidden_dim=config.hidden_dims, output_dim=12)\n",
    "\n",
    "    LitGNN_sys = LitGNN(model=model, lr=config.learning_rate, model_type= config.model_type)\n",
    "\n",
    "\n",
    "    trainer = pl.Trainer(gpus=1, max_epochs=20,logger=wandb_logger, check_val_every_n_epoch=3, precision=16,  profiler=True)  #precision=16, callbacks=[early_stop_callback],limit_train_batches=0.5, progress_bar_refresh_rate=20, \n",
    "    \n",
    "    print(\"############### TRAIN ####################\")\n",
    "    trainer.fit(LitGNN_sys, train_dataloader, val_dataloader)   \n",
    "\n",
    "    print(\"############### TEST ####################\")\n",
    "    trainer.test(test_dataloaders=test_dataloader)\n",
    "\n",
    "\n",
    "\n",
    "total_epoch = 20\n",
    "learning_rate =1e-3\n",
    "hidden_dims=256\n",
    "model_type= 'gat'\n",
    "\n",
    "sweep_config = {\n",
    "\"name\": \"Sweep pynb\",\n",
    "\"method\": \"grid\",\n",
    "\"metric\": {\n",
    "  'name': 'val/Loss',\n",
    "  'goal': 'minimize'   \n",
    "        },\n",
    "\"parameters\": {\n",
    "        \"batch_size\": {\n",
    "            \"values\": [32,64,128]\n",
    "        },\n",
    "        \"hidden_dims\": {\n",
    "            \"values\": [64, 128, 256]\n",
    "        },\n",
    "        \"model_type\": {\n",
    "            \"values\": ['gcn', 'gat', 'gated']\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"dbu_graph\")\n",
    "\n",
    "wandb.agent(sweep_id, sweep_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Lightningmodel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "\n",
    "class LitGCN(pl.LightningModule):\n",
    "    def __init__(self, model: nn.Module = My_GAT, lr: float = 1e-3, batch_size: int = 64):\n",
    "        super().__init__()\n",
    "        self.model= model\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        #self.epoch=0\n",
    "        \n",
    "        self.overall_loss_train=[]\n",
    "        \n",
    "        self.overall_num_list=[]\n",
    "        self.overall_x2y2_list=[]\n",
    "        \n",
    "        self.test_overall_num_list=[]\n",
    "        self.test_overall_x2y2_list=[]\n",
    "        \n",
    "        wandb.watch(self.model, log=\"all\")\n",
    "        \n",
    "    \n",
    "    def forward(self, graph, feats,e_w,snorm_n,snorm_e):\n",
    "        pred = self.model(graph, feats,e_w,snorm_n,snorm_e)   #inference\n",
    "        return pred\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        opt = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return opt\n",
    "    \n",
    "    def compute_RMSE_batch(self,pred, gt, mask): \n",
    "        pred=pred.view(pred.shape[0],mask.shape[1],-1)\n",
    "        pred = pred*mask #B*V,T,C  (B n grafos en el batch)\n",
    "        gt = gt*mask  # outputmask BV,T,C\n",
    "        x2y2_error=torch.sum(torch.abs(pred-gt)**2,dim=-1) # x^2+y^2 BV,T\n",
    "        overall_sum_time = x2y2_error.sum(dim=-2)  #T - suma de los errores (x^2+y^2) de los V agentes\n",
    "        overall_num = mask.sum(dim=-1).type(torch.int)  #torch.Tensor[(T)] - num de agentes (Y CON DATOS) en cada frame\n",
    "        return overall_sum_time, overall_num, x2y2_error\n",
    "\n",
    "    \n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        batched_graph, output_masks,snorm_n, snorm_e = train_batch\n",
    "        \n",
    "        feats = batched_graph.ndata['x'].float().to(dev)\n",
    "        #reshape to have shape (B*V,T*C) [c1,c2,...,c6]\n",
    "        feats = feats.view(feats.shape[0],-1)\n",
    "        e_w = batched_graph.edata['w'].float().to(dev)\n",
    "        labels= batched_graph.ndata['gt'].float().to(dev)\n",
    "        pred = self.model(batched_graph, feats,e_w,snorm_n,snorm_e)\n",
    "        overall_sum_time, overall_num, _ = self.compute_RMSE_batch(pred, labels, output_masks)  #(B,6)\n",
    "        total_loss=torch.sum(overall_sum_time)/torch.sum(overall_num.sum(dim=-2))\n",
    "        self.overall_loss_train.extend([total_loss.data.item()])\n",
    "        # Log metrics\n",
    "        self.logger.log_metrics({\"Train/loss\": total_loss.data.item()}, step=self.current_epoch)\n",
    "\n",
    "        return total_loss\n",
    "    '''\n",
    "    def training_epoch_end(self, total_loss):\n",
    "        #self.epoch += 1\n",
    "        print('|{}| Train_loss: {}'.format(datetime.now(), np.sum(self.overall_loss_train)/len(self.overall_loss_train)))\n",
    "        wandb.log({\"Train/loss\": np.sum(self.overall_loss_train)/len(self.overall_loss_train)}, step=self.epoch)\n",
    "        self.overall_loss_train=[]\n",
    "    '''\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        batched_graph, output_masks,snorm_n, snorm_e = val_batch\n",
    "        feats = batched_graph.ndata['x'].float()\n",
    "        #reshape to have shape (B*V,T*C) [c1,c2,...,c6]\n",
    "        feats = feats.view(feats.shape[0],-1)\n",
    "        e_w = batched_graph.edata['w'].float()\n",
    "        labels= batched_graph.ndata['gt'].float()\n",
    "        pred = model(batched_graph, feats,e_w,snorm_n,snorm_e)\n",
    "        _, overall_num, x2y2_error = self.compute_RMSE_batch(pred, labels, output_masks)\n",
    "        self.overall_num_list.extend(overall_num.detach().cpu().numpy())\n",
    "        self.overall_x2y2_list.extend((x2y2_error**0.5).detach().cpu().numpy())  \n",
    "        overall_loss_time = np.sum((x2y2_error**0.5).detach().cpu().numpy(), axis=0) / np.sum(overall_num.detach().cpu().numpy(), axis=0)#T\n",
    "        self.logger.log_metrics({'val/Loss':np.sum(overall_loss_time)}, step= self.current_epoch)\n",
    "    \n",
    "    '''    \n",
    "    def validation_epoch_end(self, val_results):\n",
    "        overall_sum_time=np.sum(self.overall_x2y2_list,axis=0)  #BV,T->T RMSE medio en cada T\n",
    "        overall_num_time =np.sum(self.overall_num_list, axis=0)\n",
    "        overall_loss_time=(overall_sum_time / overall_num_time) #media del error de cada agente en cada frame\n",
    "        \n",
    "        self.overall_num_list=[]\n",
    "        self.overall_x2y2_list=[]\n",
    "        #self.log('val_loss',val_loss_sum,prog_bar=True, logger=True, on_epoch=True)\n",
    "        wandb.log({\"Val/Loss\": np.sum(overall_loss_time)}, step=self.epoch)\n",
    "    '''\n",
    "    \n",
    "    def test_step(self, test_batch, batch_idx):\n",
    "        batched_graph, output_masks,snorm_n, snorm_e = test_batch\n",
    "        feats = batched_graph.ndata['x'].float().to(dev)\n",
    "        #reshape to have shape (B*V,T*C) [c1,c2,...,c6]\n",
    "        feats = feats.view(feats.shape[0],-1)\n",
    "        e_w = batched_graph.edata['w'].float().to(dev)\n",
    "        #for GatedGCN\n",
    "        #e_w= e_w.view(e_w.shape[0],1)\n",
    "        labels= batched_graph.ndata['gt'].float().to(dev)\n",
    "        pred = model(batched_graph, feats,e_w,snorm_n,snorm_e)\n",
    "        _, overall_num, x2y2_error = self.compute_RMSE_batch(pred, labels, output_masks)\n",
    "        self.test_overall_num_list.extend(overall_num.detach().cpu().numpy())\n",
    "        self.test_overall_x2y2_list.extend((x2y2_error**0.5).detach().cpu().numpy()) #BV,T\n",
    "        overall_loss_time = np.sum((x2y2_error**0.5).detach().cpu().numpy(), axis=0) / np.sum(overall_num.detach().cpu().numpy(),axis=0) #T\n",
    "        self.log('test/loss', np.sum(overall_loss_time))\n",
    "        self.log('test/loss_per_sec', overall_loss_time)\n",
    "    '''    \n",
    "    def test_epoch_end(self,test_results):\n",
    "        overall_sum_time=np.sum(self.test_overall_x2y2_list,axis=0)  #BV,T->T RMSE medio en cada T\n",
    "        overall_num_time =np.sum(self.test_overall_num_list, axis=0)\n",
    "        overall_loss_time=(overall_sum_time / overall_num_time)\n",
    "        self.log('test/loss', np.sum(overall_loss_time))\n",
    "        #self.log('test/loss_per_sec',' '.join(['{:.3f}'.format(x) for x in list(overall_loss_time)]))\n",
    "        self.log('test/loss_per_sec', overall_loss_time)\n",
    "    '''\n",
    "            \n",
    "total_epoch = 20\n",
    "lr =1e-3\n",
    "hidden_dims=256\n",
    "model_type= 'gat'\n",
    "\n",
    "\n",
    "\n",
    "wandb.init(project=\"dbu_graph\", config={\"epochs\": total_epoch, \"batch_size\": batch_size, \"learning_rate\": lr,\"model_architecture\": model, \"model_type\":model_type \"hidden_dims\": hidden_dims})\n",
    "config = wandb.config\n",
    "wandb_logger = pl_loggers.WandbLogger(save_dir='./logs/')  #name=\n",
    "\n",
    "\n",
    "if model_type == 'gat':\n",
    "    model = My_GAT(input_dim=18, hidden_dim=hidden_dims, output_dim=12)\n",
    "elif model_type == 'gcn':\n",
    "    model = model = GCN(in_feats=18, hid_feats=hidden_dims, out_feats=12)\n",
    "elif model_type == 'gated':\n",
    "    model = GatedGCN(input_dim=18, hidden_dim=hidden_dims, output_dim=12)\n",
    "    \n",
    "#init model\n",
    "LitGCN = LitGCN(model=model, lr=lr)\n",
    "    \n",
    "# most basic trainer, uses good defaults (auto-tensorboard, checkpoints, logs, and more)\n",
    "# trainer = pl.Trainer(gpus=8) (if you have GPUs)\n",
    "# using only half the training data and checking validation every quarter of a training epoch\n",
    "early_stop_callback = EarlyStopping(\n",
    "   monitor='val_loss',\n",
    "   min_delta=0.00,\n",
    "   patience=3,\n",
    "   verbose=False,\n",
    "   mode='max'\n",
    ")\n",
    "trainer = pl.Trainer(gpus=1, lr=config.learning_rate, logger=wandb_logger, max_epochs=config.epochs, progress_bar_refresh_rate=20, precision=16, profiler=True)  #val_check_interval=0.25\n",
    "\n",
    "import pdb; pdb.set_trace()\n",
    "train_dataloader=DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=8,  collate_fn=collate_batch)\n",
    "val_dataloader=DataLoader(val_dataset, batch_size=config.batch_size, shuffle=True,  collate_fn=collate_batch)\n",
    "\n",
    "trainer.fit(LitGCN, train_dataloader, val_dataloader)\n",
    "trainer.test(test_dataloaders=test_dataloader)\n",
    "\n",
    "!tensorboard --logdir ./lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train (wandb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2rr3ybqs) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 11589<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b26407c39a0645589e8d7c4401c8105a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/sandra/PROGRAMAS/DBU_Graph/wandb/run-20201123_112613-2rr3ybqs/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/sandra/PROGRAMAS/DBU_Graph/wandb/run-20201123_112613-2rr3ybqs/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Train/loss</td><td>41.09931</td></tr><tr><td>Val/Loss</td><td>19.43672</td></tr><tr><td>_step</td><td>19</td></tr><tr><td>_runtime</td><td>3123</td></tr><tr><td>_timestamp</td><td>1606130300</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Train/loss</td><td>█▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Val/Loss</td><td>█▇▅▃▃▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁</td></tr><tr><td>_step</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>_runtime</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">devoted-vortex-357</strong>: <a href=\"https://wandb.ai/sandracl72/dbu_graph/runs/2rr3ybqs\" target=\"_blank\">https://wandb.ai/sandracl72/dbu_graph/runs/2rr3ybqs</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:2rr3ybqs). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.11<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">lilac-bush-382</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/sandracl72/dbu_graph\" target=\"_blank\">https://wandb.ai/sandracl72/dbu_graph</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/sandracl72/dbu_graph/runs/smkujiru\" target=\"_blank\">https://wandb.ai/sandracl72/dbu_graph/runs/smkujiru</a><br/>\n",
       "                Run data is saved locally in <code>/home/sandra/PROGRAMAS/DBU_Graph/wandb/run-20201123_121820-smkujiru</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/54 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:04<00:00, 11.75it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:18:29.027149| Train_loss: 248.10219628435902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:01<00:00, 12.04it/s]\n",
      "  0%|          | 0/54 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:18:30.281411| Val_loss: 3.369 4.933 6.705 8.644 10.627 12.361 46.638\n",
      "Epoch:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:04<00:00, 11.37it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:18:35.035685| Train_loss: 107.97459730403568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:01<00:00, 10.42it/s]\n",
      "  0%|          | 0/54 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:18:36.483363| Val_loss: 2.413 3.532 4.951 6.306 7.959 9.607 34.768\n",
      "Epoch:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:06<00:00,  8.88it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:18:42.566731| Train_loss: 80.19130064544213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:01<00:00,  9.72it/s]\n",
      "  0%|          | 0/54 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:18:44.118670| Val_loss: 2.335 3.201 4.193 5.314 6.475 7.522 29.040\n",
      "Epoch:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:04<00:00, 11.15it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:18:48.968545| Train_loss: 66.27676837618286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:01<00:00, 11.92it/s]\n",
      "  0%|          | 0/54 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:18:50.240045| Val_loss: 2.039 2.768 3.724 4.809 6.113 6.982 26.436\n",
      "Epoch:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:05<00:00, 10.68it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:18:55.299557| Train_loss: 59.06688113876339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:01<00:00, 11.61it/s]\n",
      "  0%|          | 0/54 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:18:56.599414| Val_loss: 1.925 2.801 3.880 5.146 6.153 7.477 27.382\n",
      "Epoch:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:04<00:00, 10.82it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:19:01.594612| Train_loss: 55.09809917299031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:01<00:00, 12.20it/s]\n",
      "  0%|          | 0/54 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:19:02.831612| Val_loss: 2.017 2.851 3.834 4.777 5.771 6.826 26.076\n",
      "Epoch:  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:06<00:00,  8.56it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:19:09.143360| Train_loss: 50.64386848099544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:01<00:00,  9.37it/s]\n",
      "  0%|          | 0/54 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:19:10.752347| Val_loss: 1.769 2.609 3.485 4.510 5.572 6.680 24.626\n",
      "Epoch:  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:05<00:00, 10.22it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:19:16.042627| Train_loss: 48.00181720556836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:01<00:00, 12.64it/s]\n",
      "  0%|          | 0/54 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:19:17.236830| Val_loss: 1.519 2.327 3.280 4.344 5.315 6.290 23.075\n",
      "Epoch:  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:05<00:00,  9.57it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:19:22.885362| Train_loss: 45.27211490954804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:01<00:00, 11.32it/s]\n",
      "  0%|          | 0/54 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:19:24.223352| Val_loss: 1.488 2.272 3.072 3.970 5.033 5.995 21.830\n",
      "Epoch:  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:05<00:00,  9.23it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:19:30.081320| Train_loss: 44.24516540712264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:01<00:00,  9.82it/s]\n",
      "  0%|          | 0/54 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:19:31.616242| Val_loss: 1.556 2.280 3.066 3.944 4.896 5.901 21.643\n",
      "Epoch:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:04<00:00, 11.08it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:19:36.495303| Train_loss: 42.02405644363767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:01<00:00, 11.86it/s]\n",
      "  0%|          | 0/54 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:19:37.767887| Val_loss: 1.455 2.100 2.838 3.788 4.632 5.509 20.322\n",
      "Epoch:  11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:05<00:00,  9.89it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:19:43.231296| Train_loss: 41.51003862487578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:01<00:00, 12.20it/s]\n",
      "  0%|          | 0/54 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:19:44.468023| Val_loss: 1.438 2.028 2.760 3.609 4.513 5.433 19.781\n",
      "Epoch:  12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:06<00:00,  8.69it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:19:50.686561| Train_loss: 39.48724932153695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:01<00:00, 10.74it/s]\n",
      "  0%|          | 0/54 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:19:52.092918| Val_loss: 1.460 2.185 2.942 3.776 4.621 5.620 20.603\n",
      "Epoch:  13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:05<00:00, 10.15it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:19:57.415677| Train_loss: 39.17748710902207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:01<00:00, 10.18it/s]\n",
      "  0%|          | 0/54 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:19:58.897537| Val_loss: 1.313 2.077 2.901 3.731 4.646 5.564 20.232\n",
      "Epoch:  14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:04<00:00, 10.99it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:20:03.815531| Train_loss: 37.72422794959403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:01<00:00, 12.38it/s]\n",
      "  0%|          | 0/54 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:20:05.035717| Val_loss: 1.391 2.016 2.762 3.552 4.460 5.428 19.609\n",
      "Epoch:  15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:05<00:00, 10.65it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:20:10.111809| Train_loss: 36.884593490668486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:01<00:00, 12.21it/s]\n",
      "  0%|          | 0/54 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:20:11.348312| Val_loss: 1.429 2.102 2.881 3.609 4.501 5.308 19.830\n",
      "Epoch:  16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:04<00:00, 10.92it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:20:16.300154| Train_loss: 38.0419973078066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:01<00:00, 11.81it/s]\n",
      "  0%|          | 0/54 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:20:17.578012| Val_loss: 1.328 1.967 2.819 3.622 4.431 5.299 19.465\n",
      "Epoch:  17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:05<00:00, 10.25it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:20:22.849221| Train_loss: 36.39359295286782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:01<00:00, 12.19it/s]\n",
      "  0%|          | 0/54 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:20:24.087816| Val_loss: 1.523 2.173 2.939 3.738 4.626 5.529 20.527\n",
      "Epoch:  18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:04<00:00, 10.84it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:20:29.072114| Train_loss: 35.6739748043812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:01<00:00, 12.41it/s]\n",
      "  0%|          | 0/54 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:20:30.288682| Val_loss: 1.304 1.875 2.618 3.382 4.186 5.092 18.457\n",
      "Epoch:  19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:04<00:00, 11.14it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:20:35.138735| Train_loss: 34.76627860519767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:01<00:00, 12.09it/s]\n",
      "  0%|          | 0/54 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:20:36.387889| Val_loss: 1.379 1.993 2.695 3.491 4.308 5.198 19.064\n",
      "Epoch:  20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:05<00:00, 10.47it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:20:41.549208| Train_loss: 34.25017349042532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:01<00:00, 12.35it/s]\n",
      "  0%|          | 0/54 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:20:42.771287| Val_loss: 1.345 1.888 2.642 3.440 4.259 5.223 18.796\n",
      "Epoch:  21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:05<00:00, 10.57it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:20:47.884140| Train_loss: 35.1730455262705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:01<00:00, 11.83it/s]\n",
      "  0%|          | 0/54 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:20:49.159669| Val_loss: 1.317 1.893 2.649 3.375 4.143 5.005 18.382\n",
      "Epoch:  22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:05<00:00, 10.75it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:20:54.188924| Train_loss: 33.88380418133601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:01<00:00, 11.12it/s]\n",
      "  0%|          | 0/54 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:20:55.546148| Val_loss: 1.250 1.786 2.494 3.258 4.082 4.987 17.857\n",
      "Epoch:  23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:05<00:00, 10.58it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:21:00.656280| Train_loss: 33.04449230961211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:01<00:00, 10.90it/s]\n",
      "  0%|          | 0/54 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:21:02.040882| Val_loss: 1.252 1.813 2.450 3.208 4.009 4.853 17.585\n",
      "Epoch:  24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:05<00:00,  9.73it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:21:07.595251| Train_loss: 32.63191638365863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:01<00:00, 12.75it/s]\n",
      "  0%|          | 0/54 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:21:08.780623| Val_loss: 1.322 1.978 2.759 3.584 4.443 5.304 19.390\n",
      "Epoch:  25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:05<00:00, 10.49it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:21:13.930962| Train_loss: 33.93350810927785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:01<00:00, 12.03it/s]\n",
      "  0%|          | 0/54 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:21:15.189753| Val_loss: 1.260 1.815 2.487 3.183 3.955 4.746 17.447\n",
      "Epoch:  26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:05<00:00, 10.41it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:21:20.383253| Train_loss: 32.93819954698767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:01<00:00, 12.01it/s]\n",
      "  0%|          | 0/54 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:21:21.641229| Val_loss: 1.265 1.760 2.459 3.182 3.987 4.871 17.524\n",
      "Epoch:  27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:05<00:00, 10.50it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:21:26.788581| Train_loss: 31.970731316673433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:01<00:00, 12.36it/s]\n",
      "  0%|          | 0/54 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:21:28.010490| Val_loss: 1.275 1.825 2.478 3.198 3.992 4.839 17.608\n",
      "Epoch:  28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:05<00:00, 10.26it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:21:33.279645| Train_loss: 32.4484667975819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:01<00:00, 11.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-23 12:21:34.642405| Val_loss: 1.256 1.861 2.583 3.357 4.111 4.967 18.135\n",
      "Early stopping: \n",
      "Difference: 0.0\n",
      "Successfully saved to ./models_checkpoints/gat_bt64bv64_hid256_lr0.001_ep050.pt\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#train_iter=iter(train_dataloader)\n",
    "import wandb\n",
    "wandb.init(project=\"dbu_graph\")\n",
    "\n",
    "work_dir = './models_checkpoints'\n",
    "model_type = 'gat'\n",
    "hidden_dims=256\n",
    "batch_train=64\n",
    "batch_val=64\n",
    "base_lr=1e-3\n",
    "total_epoch=50\n",
    "\n",
    "def my_save_model(model):\n",
    "    path = '{}/{}_bt{}bv{}_hid{}_lr{}_ep{:03}.pt'.format(work_dir, model_type, batch_train,batch_val, hidden_dims, base_lr, total_epoch)\n",
    "    if os.path.exists(path):\n",
    "        path= '.' + path.split('.')[1] + '_' + str(datetime.now().minute)+ '.pt'\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print('Successfully saved to {}'.format(path))\n",
    "    \n",
    "    \n",
    "\n",
    "def compute_RMSE_batch(pred, gt, mask): \n",
    "    #output mask vale 0 si no visible o no-car o visible pero no hay datos en ese frame  (B*V,T,1), cada fila un nodo de un grafo perteneciente al batch\n",
    "    pred=pred.view(pred.shape[0],mask.shape[1],-1)\n",
    "    #gt=gt.view(pred.shape[0],6,-1)\n",
    "    \n",
    "    pred = pred*mask #B*V,T,C  (B n grafos en el batch)\n",
    "    gt = gt*mask  # outputmask BV,T,C\n",
    "    \n",
    "    x2y2_error=torch.sum(torch.abs(pred-gt)**2,dim=-1) # x^2+y^2 BV,T\n",
    "    overall_sum_time = x2y2_error.sum(dim=-2)  #T - suma de los errores (x^2+y^2) de los V agentes\n",
    "    overall_num = mask.sum(dim=-1).type(torch.int)  #torch.Tensor[(T)] - num de agentes (Y CON DATOS) en cada frame\n",
    "    return overall_sum_time, overall_num, x2y2_error\n",
    "\n",
    "\n",
    "def val(model, val_dataloader,val_loss_sum):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        overall_num_list=[] \n",
    "        overall_x2y2_list=[]\n",
    "        for batched_graph, output_masks,snorm_n, snorm_e in tqdm(val_dataloader):\n",
    "            feats = batched_graph.ndata['x'].float().to(dev)\n",
    "            #reshape to have shape (B*V,T*C) [c1,c2,...,c6]\n",
    "            feats = feats.view(feats.shape[0],-1)\n",
    "            e_w = batched_graph.edata['w'].float().to(dev)\n",
    "            \n",
    "            if model == 'gated':\n",
    "                e_w= e_w.view(e_w.shape[0],1)\n",
    "            \n",
    "            labels= batched_graph.ndata['gt'].float().to(dev)\n",
    "            #labels = labels.view(labels.shape[0], -1)\n",
    "            pred = model(batched_graph.to(dev), feats,e_w,snorm_n,snorm_e)\n",
    "            _, overall_num, x2y2_error = compute_RMSE_batch(pred, labels, output_masks.to(dev))\n",
    "            #print(x2y2_error.shape)  #BV,T\n",
    "            overall_num_list.extend(overall_num.detach().cpu().numpy())\n",
    "            #print(overall_num.shape)  #BV,T\n",
    "            overall_x2y2_list.extend((x2y2_error**0.5).detach().cpu().numpy())  #RMSE para cada nodo en cada T\n",
    "            \n",
    "    overall_sum_time=np.sum(overall_x2y2_list,axis=0)  #BV,T->T RMSE medio en cada T\n",
    "    overall_num_time =np.sum(overall_num_list, axis=0)\n",
    "    overall_loss_time=(overall_sum_time / overall_num_time) #media del error de cada agente en cada frame\n",
    "\n",
    "    print('|{}| Val_loss: {}'.format(datetime.now(), ' '.join(['{:.3f}'.format(x) for x in list(overall_loss_time) + [np.sum(overall_loss_time)]])))\n",
    "    val_loss_sum.append(np.sum(overall_loss_time))\n",
    "    wandb.log({'Val/Loss': val_loss_sum[-1] }, step=epoch)\n",
    "    \n",
    "\n",
    "dev='cuda:0'\n",
    "if model_type == 'gat':\n",
    "    model = My_GAT(input_dim=24, hidden_dim=hidden_dims, output_dim=12,dropout=0.25, feat_drop=0., attn_drop=0.).to(dev)\n",
    "elif model_type == 'gcn':\n",
    "    model = model = GCN(in_feats=24, hid_feats=hidden_dims, out_feats=12, dropout=0.25).to(dev)\n",
    "elif model_type == 'gated':\n",
    "    model = GatedGCN(input_dim=24, hidden_dim=hidden_dims, output_dim=12).to(dev)\n",
    "\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=base_lr)\n",
    "np.seterr(all='raise')\n",
    "train_loss_sum=[]\n",
    "val_loss_sum=[]\n",
    "val_loss_prev=0\n",
    "patience=0\n",
    "wandb.watch(model, log='all')\n",
    "n_epochs=0\n",
    "    \n",
    "for epoch in range(total_epoch):\n",
    "    \n",
    "    print(\"Epoch: \",epoch)\n",
    "    overall_loss_train=[]\n",
    "    model.train()\n",
    "    n_epochs=epoch+1\n",
    "    \n",
    "    for batch_graphs, masks, batch_snorm_n, batch_snorm_e in tqdm(train_dataloader):\n",
    "        feats = batch_graphs.ndata['x'].float().to(dev)\n",
    "        feats=feats.view(feats.shape[0],-1)  #Nx18\n",
    "        batch_e = batch_graphs.edata['w'].float().to(dev)\n",
    "        #for GATED GCN\n",
    "        if model == 'gated':\n",
    "            batch_e=batch_e.view(batch_e.shape[0],1)\n",
    "        #model = GatedGCN(input_dim=18, hidden_dim=256, output_dim=12).to(dev)\n",
    "        batch_pred = model(batch_graphs.to(dev), feats, batch_e, batch_snorm_n.to(dev), batch_snorm_e.to(dev))\n",
    "        #print(batch_pred.shape, masks.shape)\n",
    "\n",
    "        labels= batch_graphs.ndata['gt'].float().to(dev)\n",
    "        overall_sum_time, overall_num, _ = compute_RMSE_batch(batch_pred, labels, masks.to(dev))  #(B,6)\n",
    "        total_loss=torch.sum(overall_sum_time)/torch.sum(overall_num.sum(dim=-2))\n",
    "        opt.zero_grad() \n",
    "        total_loss.backward()\n",
    "        #print(model.embedding_h.weight.grad) #model.GatedGCN1.A.weight.grad)\n",
    "        opt.step()\n",
    "        overall_loss_train.extend([total_loss.data.item()])\n",
    "        \n",
    "    print('|{}| Train_loss: {}'.format(datetime.now(), np.sum(overall_loss_train)/len(overall_loss_train)))\n",
    "    train_loss_sum.append(np.sum(overall_loss_train)/len(overall_loss_train))\n",
    "    wandb.log({\"Train/loss\": train_loss_sum[-1]}, step=epoch)\n",
    "    \n",
    "    val(model, val_dataloader, val_loss_sum)\n",
    "    \n",
    "    if val_loss_prev < val_loss_sum[-1] and epoch !=0:\n",
    "        patience+=1\n",
    "        val_loss_prev = val_loss_sum[-1]\n",
    "    else:\n",
    "        patience = 0\n",
    "        val_loss_prev = val_loss_sum[-1]\n",
    "        \n",
    "    if patience > 2:\n",
    "        print(\"Early stopping: \")\n",
    "        print(\"Difference: {}\".format(val_loss_prev-val_loss_sum[-1]))\n",
    "        break\n",
    "        \n",
    "        \n",
    "my_save_model(model)\n",
    "\n",
    "#torch.save(model.state_dict(), os.path.join(wandb.run.dir, 'model.pt'))\n",
    "\n",
    "epochs = list(range(epoch+1))\n",
    "plt.ion() #Turn the interactive mode on\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epochs,train_loss_sum)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Train Loss')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epochs,val_loss_sum)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Val Loss')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gcn_model = GCN(in_feats=18, hid_feats=256, out_feats=12).to(dev)\n",
    "gat_model = My_GAT(input_dim=18, hidden_dim=256, output_dim=12).to(dev)\n",
    "gat_model.load_state_dict(torch.load('./models_checkpoints/gat_bt64bv32_hid256_lr0.001_ep040.pt_39'))\n",
    "#gcn_model.load_state_dict(torch.load('./models_checkpoints/gcn_256_b64_ep40_embed.pth'))\n",
    "\n",
    "#print(gcn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230/230 [00:03<00:00, 61.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-17 08:45:32.988859| Test_RMSE: 1.327 2.104 2.786 3.355 4.026 4.655 18.254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nwith torch.no_grad():\\n\\n    for batched_graph, output_masks,snorm_n, snorm_e,last_vis_obj in tqdm(test_dataloader):\\n        feats = batched_graph.ndata['x'].float().to(dev)\\n        feats = feats.view(feats.shape[0],-1)\\n        e_w = batched_graph.edata['w'].float().to(dev)\\n        labels= batched_graph.ndata['gt'].float().to(dev)\\n        pred = gat_model(batched_graph, feats,e_w,snorm_n,snorm_e)\\n        _, overall_num, x2y2_error = compute_RMSE_batch(pred, labels, output_masks)\\n        xy_error = (x2y2_error**0.5).detach().cpu().numpy() #BV,T\\n        overall_num = overall_num.detach().cpu().numpy()\\n        xy_s1_list.extend(xy_error[:,:2])\\n        xy_s2_list.extend(xy_error[:,2:4])\\n        xy_s3_list.extend(xy_error[:,4:])\\n        num_s1_list.extend(overall_num[:,:2])\\n        num_s2_list.extend(overall_num[:,2:4])\\n        num_s3_list.extend(overall_num[:,4:])\\n        \\n                \\noverall_sum_s1=np.sum(xy_s1_list,axis=0)  #BV,T->T\\noverall_sum_s2=np.sum(xy_s2_list,axis=0)\\noverall_sum_s3=np.sum(xy_s3_list,axis=0)\\noverall_num_s1 =np.sum(num_s1_list, axis=0)\\noverall_num_s2 =np.sum(num_s2_list, axis=0)\\noverall_num_s3 =np.sum(num_s3_list, axis=0)\\n    \\noverall_loss_s1=(overall_sum_s1 / overall_num_s1)#media del error de cada agente en cada frame\\noverall_loss_s2=(overall_sum\\n_s2 / overall_num_s2)\\noverall_loss_s3=(overall_sum_s3 / overall_num_s3)\\n\\nprint('Test_loss_sec1: average: {}'.format(overall_loss_s1))\\nprint('Test_loss_sec2: average: {}'.format(overall_loss_s2))\\nprint('Test_loss_sec3: average: {}'.format(overall_loss_s3))\\n      \\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "xy_s1_list= []\n",
    "xy_s2_list= []\n",
    "xy_s3_list= []\n",
    "num_s1_list= []\n",
    "num_s2_list= []\n",
    "num_s3_list= []\n",
    "\n",
    "gat_model.eval()\n",
    "with torch.no_grad():\n",
    "    overall_num_list=[] \n",
    "    overall_x2y2_list=[]\n",
    "    for batched_graph, output_masks,snorm_n, snorm_e in tqdm(test_dataloader):\n",
    "        feats = batched_graph.ndata['x'].float().to(dev)\n",
    "        feats = feats.view(feats.shape[0],-1)\n",
    "        e_w = batched_graph.edata['w'].float().to(dev)\n",
    "\n",
    "        #for GatedGCN\n",
    "        #e_w= e_w.view(e_w.shape[0],1)\n",
    "\n",
    "        labels= batched_graph.ndata['gt'][:,:,:].float().to(dev)\n",
    "        #labels = labels.view(labels.shape[0], -1)\n",
    "        pred = gat_model(batched_graph, feats,e_w,snorm_n,snorm_e)\n",
    "        _, overall_num, x2y2_error = compute_RMSE_batch(pred, labels, output_masks[:,:,:])\n",
    "        #print(x2y2_error.shape)  #BV,T\n",
    "        overall_num_list.extend(overall_num.detach().cpu().numpy())\n",
    "        #print(overall_num.shape)  #BV,T\n",
    "        overall_x2y2_list.extend((x2y2_error**0.5).detach().cpu().numpy())  #RMSE para cada nodo en cada T\n",
    "\n",
    "overall_sum_time=np.sum(overall_x2y2_list,axis=0)  #BV,T->T RMSE medio en cada T\n",
    "overall_num_time =np.sum(overall_num_list, axis=0)\n",
    "overall_loss_time=(overall_sum_time / overall_num_time) #media del error de cada agente en cada frame\n",
    "\n",
    "print('|{}| Test_RMSE: {}'.format(datetime.now(), ' '.join(['{:.3f}'.format(x) for x in list(overall_loss_time) + [np.sum(overall_loss_time)]])))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pDL] *",
   "language": "python",
   "name": "conda-env-pDL-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
