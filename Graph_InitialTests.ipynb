{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "os.environ['DGLBACKEND'] = 'pytorch'\n",
    "from dgl import DGLGraph\n",
    "import numpy as np\n",
    "import scipy.sparse as spp\n",
    "from scipy import spatial\n",
    "from tqdm import tqdm\n",
    "from dgl.data import DGLDataset\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from ApolloScape_Dataset import ApolloScape_DGLDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ApolloScape_DGLDataset(train_val='train') #3447\n",
    "val_dataset = ApolloScape_DGLDataset(train_val='val')  #919\n",
    "test_dataset = ApolloScape_DGLDataset(train_val='test')  #230\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collate function to prepare graphs\n",
    "def collate_batch(samples):\n",
    "    graphs, masks, last_vis_obj = map(list, zip(*samples))  # samples is a list of pairs (graph, mask) mask es VxTx1\n",
    "    masks = np.vstack(masks)\n",
    "    masks = torch.tensor(masks)#+torch.zeros(2)\n",
    "    #masks = masks.view(masks.shape[0],-1)\n",
    "    #masks= masks.view(masks.shape[0]*masks.shape[1],masks.shape[2],masks.shape[3])#.squeeze(0) para TAMAÑO FIJO\n",
    "    sizes_n = [graph.number_of_nodes() for graph in graphs] # graph sizes\n",
    "    snorm_n = [torch.FloatTensor(size, 1).fill_(1 / size) for size in sizes_n]\n",
    "    snorm_n = torch.cat(snorm_n).sqrt()  # graph size normalization \n",
    "    sizes_e = [graph.number_of_edges() for graph in graphs] # nb of edges\n",
    "    snorm_e = [torch.FloatTensor(size, 1).fill_(1 / size) for size in sizes_e]\n",
    "    snorm_e = torch.cat(snorm_e).sqrt()  # graph size normalization\n",
    "    batched_graph = dgl.batch(graphs)  # batch graphs\n",
    "    return batched_graph.to(dev), masks.to(dev), snorm_n.to(dev), snorm_e.to(dev), last_vis_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 6, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev='cuda'\n",
    "train_dataloader=DataLoader(train_dataset, batch_size=64, shuffle=False, collate_fn=collate_batch)\n",
    "val_dataloader=DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_batch)\n",
    "test_dataloader=DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=collate_batch)  \n",
    "batched_graph, masks, snorm_n, snorm_e, last_vis_obj=next(iter(test_dataloader))\n",
    "masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([948, 6, 1])\n",
      "torch.Size([773, 6, 1])\n",
      "torch.Size([23, 6, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "919"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_graph, masks, snorm_n, snorm_e, last_vis_obj=next(iter(train_dataloader))\n",
    "print(masks.shape)\n",
    "batched_graph, masks, snorm_n, snorm_e, last_vis_obj=next(iter(val_dataloader))\n",
    "print(masks.shape)\n",
    "batched_graph, masks, snorm_n, snorm_e, last_vis_obj=next(iter(test_dataloader))\n",
    "print(masks.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5010, 120, 12, 11)\n"
     ]
    }
   ],
   "source": [
    "with open('../DBU_Graph/data/apollo_train_data.pkl', 'rb') as reader:\n",
    "    [feat,adj, mean]=pickle.load(reader)\n",
    "    \n",
    "feat=np.transpose(feat, (0,3,2,1))\n",
    "print(feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#pruebas def preprocess_data de main.py (GRIP) \\nfeature_id = [3, 4, 9, 10]  #x,y,heading,[visible_mask]\\nvel_data = feat[:,feature_id]  # N,C,T,V\\nvel_mask = (vel_data[:, :2, 1:]!=0) * (vel_data[:, :2, :-1]!=0) #False-> frames en los que no tenemos VELOCIDAD del obj\\nvel_data[:, :2, 1:] = (vel_data[:, :2, 1:] - vel_data[:, :2, :-1]).astype(float) * vel_mask.astype(float)\\nvel_data[:, :2, 0] = 0\\nprint(vel_data[0,:,6:,0])\\n#print(new_mask[0,:,:,0])\\n'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#pruebas def preprocess_data de main.py (GRIP) \n",
    "feature_id = [3, 4, 9, 10]  #x,y,heading,[visible_mask]\n",
    "vel_data = feat[:,feature_id]  # N,C,T,V\n",
    "vel_mask = (vel_data[:, :2, 1:]!=0) * (vel_data[:, :2, :-1]!=0) #False-> frames en los que no tenemos VELOCIDAD del obj\n",
    "vel_data[:, :2, 1:] = (vel_data[:, :2, 1:] - vel_data[:, :2, :-1]).astype(float) * vel_mask.astype(float)\n",
    "vel_data[:, :2, 0] = 0\n",
    "print(vel_data[0,:,6:,0])\n",
    "#print(new_mask[0,:,:,0])\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5010, 70, 12, 11])\n"
     ]
    }
   ],
   "source": [
    "features=torch.from_numpy(feat[:,:70,:,:]).type(torch.float32)\n",
    "print(features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13,\n",
       " 14,\n",
       " 15,\n",
       " 15,\n",
       " 17,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 24,\n",
       " 25,\n",
       " 22,\n",
       " 21,\n",
       " 21,\n",
       " 24,\n",
       " 24,\n",
       " 27,\n",
       " 25,\n",
       " 24,\n",
       " 25,\n",
       " 25,\n",
       " 28,\n",
       " 29,\n",
       " 31,\n",
       " 32,\n",
       " 32,\n",
       " 31,\n",
       " 46,\n",
       " 44,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 42,\n",
       " 41,\n",
       " 39,\n",
       " 36,\n",
       " 33,\n",
       " 29,\n",
       " 27,\n",
       " 20,\n",
       " 17,\n",
       " 16,\n",
       " 15,\n",
       " 14,\n",
       " 16,\n",
       " 15,\n",
       " 15,\n",
       " 14,\n",
       " 18,\n",
       " 16,\n",
       " 15,\n",
       " 16,\n",
       " 18,\n",
       " 17,\n",
       " 18,\n",
       " 18,\n",
       " 19,\n",
       " 18,\n",
       " 17,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 20,\n",
       " 20,\n",
       " 19,\n",
       " 17,\n",
       " 16,\n",
       " 15,\n",
       " 14,\n",
       " 15,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 22,\n",
       " 21,\n",
       " 21,\n",
       " 22,\n",
       " 21,\n",
       " 20,\n",
       " 20,\n",
       " 22,\n",
       " 22,\n",
       " 20,\n",
       " 21,\n",
       " 19,\n",
       " 20,\n",
       " 22,\n",
       " 21,\n",
       " 20,\n",
       " 17,\n",
       " 17,\n",
       " 15,\n",
       " 16,\n",
       " 16,\n",
       " 15,\n",
       " 19,\n",
       " 19,\n",
       " 17,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 20,\n",
       " 20,\n",
       " 17,\n",
       " 19,\n",
       " 18,\n",
       " 10,\n",
       " 10,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 11,\n",
       " 12,\n",
       " 12,\n",
       " 16,\n",
       " 16,\n",
       " 14,\n",
       " 15,\n",
       " 18,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 22,\n",
       " 20,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 20,\n",
       " 22,\n",
       " 21,\n",
       " 19,\n",
       " 16,\n",
       " 14,\n",
       " 13,\n",
       " 15,\n",
       " 15,\n",
       " 17,\n",
       " 18,\n",
       " 20,\n",
       " 18,\n",
       " 19,\n",
       " 25,\n",
       " 24,\n",
       " 24,\n",
       " 28,\n",
       " 26,\n",
       " 24,\n",
       " 22,\n",
       " 22,\n",
       " 20,\n",
       " 19,\n",
       " 17,\n",
       " 14,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 11,\n",
       " 10,\n",
       " 8,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 12,\n",
       " 13,\n",
       " 16,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 15,\n",
       " 15,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 13,\n",
       " 12,\n",
       " 12,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 14,\n",
       " 14,\n",
       " 13,\n",
       " 13,\n",
       " 14,\n",
       " 11,\n",
       " 12,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 19,\n",
       " 20,\n",
       " 20,\n",
       " 19,\n",
       " 20,\n",
       " 23,\n",
       " 22,\n",
       " 27,\n",
       " 29,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 31,\n",
       " 29,\n",
       " 29,\n",
       " 32,\n",
       " 29,\n",
       " 30,\n",
       " 32,\n",
       " 29,\n",
       " 31,\n",
       " 35,\n",
       " 44,\n",
       " 45,\n",
       " 48,\n",
       " 49,\n",
       " 52,\n",
       " 49,\n",
       " 44,\n",
       " 39,\n",
       " 36,\n",
       " 34,\n",
       " 32,\n",
       " 35,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 31,\n",
       " 25,\n",
       " 27,\n",
       " 24,\n",
       " 21,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 9,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 12,\n",
       " 14,\n",
       " 14,\n",
       " 15,\n",
       " 14,\n",
       " 12,\n",
       " 12,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 14,\n",
       " 13,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 10,\n",
       " 11,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 15,\n",
       " 14,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 17,\n",
       " 17,\n",
       " 20,\n",
       " 21,\n",
       " 21,\n",
       " 25,\n",
       " 21,\n",
       " 23,\n",
       " 23,\n",
       " 24,\n",
       " 23,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 28,\n",
       " 30,\n",
       " 31,\n",
       " 31,\n",
       " 30,\n",
       " 30,\n",
       " 29,\n",
       " 31,\n",
       " 30,\n",
       " 30,\n",
       " 29,\n",
       " 28,\n",
       " 29,\n",
       " 25,\n",
       " 27,\n",
       " 26,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 23,\n",
       " 22,\n",
       " 23,\n",
       " 21,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 19,\n",
       " 20,\n",
       " 26,\n",
       " 28,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 24,\n",
       " 22,\n",
       " 20,\n",
       " 22,\n",
       " 21,\n",
       " 20,\n",
       " 20,\n",
       " 19,\n",
       " 17,\n",
       " 19,\n",
       " 22,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 20,\n",
       " 18,\n",
       " 19,\n",
       " 19,\n",
       " 18,\n",
       " 16,\n",
       " 18,\n",
       " 16,\n",
       " 16,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 13,\n",
       " 13,\n",
       " 12,\n",
       " 11,\n",
       " 11,\n",
       " 12,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 9,\n",
       " 11,\n",
       " 11,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 13,\n",
       " 13,\n",
       " 12,\n",
       " 12,\n",
       " 11,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 15,\n",
       " 14,\n",
       " 12,\n",
       " 13,\n",
       " 13,\n",
       " 11,\n",
       " 11,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 10,\n",
       " 12,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 12,\n",
       " 14,\n",
       " 15,\n",
       " 18,\n",
       " 17,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 18,\n",
       " 18,\n",
       " 19,\n",
       " 19,\n",
       " 17,\n",
       " 16,\n",
       " 70,\n",
       " 65,\n",
       " 64,\n",
       " 68,\n",
       " 66,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 65,\n",
       " 67,\n",
       " 66,\n",
       " 68,\n",
       " 70,\n",
       " 67,\n",
       " 61,\n",
       " 63,\n",
       " 57,\n",
       " 53,\n",
       " 48,\n",
       " 49,\n",
       " 47,\n",
       " 45,\n",
       " 38,\n",
       " 46,\n",
       " 44,\n",
       " 45,\n",
       " 53,\n",
       " 56,\n",
       " 56,\n",
       " 54,\n",
       " 53,\n",
       " 58,\n",
       " 56,\n",
       " 53,\n",
       " 51,\n",
       " 51,\n",
       " 49,\n",
       " 49,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 56,\n",
       " 56,\n",
       " 58,\n",
       " 60,\n",
       " 60,\n",
       " 62,\n",
       " 59,\n",
       " 54,\n",
       " 59,\n",
       " 56,\n",
       " 53,\n",
       " 53,\n",
       " 50,\n",
       " 50,\n",
       " 56,\n",
       " 59,\n",
       " 56,\n",
       " 55,\n",
       " 53,\n",
       " 56,\n",
       " 55,\n",
       " 53,\n",
       " 47,\n",
       " 31,\n",
       " 27,\n",
       " 26,\n",
       " 14,\n",
       " 12,\n",
       " 19,\n",
       " 24,\n",
       " 30,\n",
       " 41,\n",
       " 46,\n",
       " 46,\n",
       " 51,\n",
       " 50,\n",
       " 52,\n",
       " 46,\n",
       " 51,\n",
       " 53,\n",
       " 57,\n",
       " 56,\n",
       " 22,\n",
       " 21,\n",
       " 20,\n",
       " 20,\n",
       " 22,\n",
       " 26,\n",
       " 31,\n",
       " 33,\n",
       " 34,\n",
       " 33,\n",
       " 28,\n",
       " 23,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 22,\n",
       " 23,\n",
       " 23,\n",
       " 22,\n",
       " 22,\n",
       " 31,\n",
       " 31,\n",
       " 33,\n",
       " 39,\n",
       " 39,\n",
       " 37,\n",
       " 33,\n",
       " 28,\n",
       " 26,\n",
       " 25,\n",
       " 20,\n",
       " 14,\n",
       " 16,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 15,\n",
       " 16,\n",
       " 21,\n",
       " 23,\n",
       " 25,\n",
       " 28,\n",
       " 27,\n",
       " 31,\n",
       " 33,\n",
       " 29,\n",
       " 32,\n",
       " 31,\n",
       " 34,\n",
       " 34,\n",
       " 34,\n",
       " 30,\n",
       " 27,\n",
       " 27,\n",
       " 26,\n",
       " 23,\n",
       " 21,\n",
       " 21,\n",
       " 22,\n",
       " 24,\n",
       " 26,\n",
       " 25,\n",
       " 27,\n",
       " 26,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 23,\n",
       " 21,\n",
       " 21,\n",
       " 20,\n",
       " 22,\n",
       " 23,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 27,\n",
       " 28,\n",
       " 28,\n",
       " 29,\n",
       " 26,\n",
       " 27,\n",
       " 25,\n",
       " 27,\n",
       " 42,\n",
       " 43,\n",
       " 39,\n",
       " 36,\n",
       " 33,\n",
       " 30,\n",
       " 27,\n",
       " 25,\n",
       " 26,\n",
       " 25,\n",
       " 27,\n",
       " 29,\n",
       " 33,\n",
       " 32,\n",
       " 33,\n",
       " 33,\n",
       " 31,\n",
       " 31,\n",
       " 29,\n",
       " 31,\n",
       " 26,\n",
       " 28,\n",
       " 28,\n",
       " 29,\n",
       " 28,\n",
       " 31,\n",
       " 31,\n",
       " 30,\n",
       " 28,\n",
       " 27,\n",
       " 25,\n",
       " 26,\n",
       " 25,\n",
       " 25,\n",
       " 24,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 24,\n",
       " 24,\n",
       " 23,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 23,\n",
       " 23,\n",
       " 22,\n",
       " 24,\n",
       " 22,\n",
       " 23,\n",
       " 21,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 21,\n",
       " 22,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 21,\n",
       " 20,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 24,\n",
       " 25,\n",
       " 22,\n",
       " 21,\n",
       " 23,\n",
       " 24,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 17,\n",
       " 16,\n",
       " 16,\n",
       " 17,\n",
       " 17,\n",
       " 19,\n",
       " 18,\n",
       " 18,\n",
       " 25,\n",
       " 30,\n",
       " 36,\n",
       " 37,\n",
       " 36,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 40,\n",
       " 43,\n",
       " 44,\n",
       " 49,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 50,\n",
       " 49,\n",
       " 40,\n",
       " 37,\n",
       " 33,\n",
       " 29,\n",
       " 28,\n",
       " 28,\n",
       " 25,\n",
       " 21,\n",
       " 21,\n",
       " 23,\n",
       " 26,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 27,\n",
       " 25,\n",
       " 25,\n",
       " 22,\n",
       " 23,\n",
       " 21,\n",
       " 21,\n",
       " 20,\n",
       " 19,\n",
       " 15,\n",
       " 15,\n",
       " 19,\n",
       " 20,\n",
       " 25,\n",
       " 24,\n",
       " 27,\n",
       " 26,\n",
       " 25,\n",
       " 21,\n",
       " 22,\n",
       " 22,\n",
       " 23,\n",
       " 23,\n",
       " 25,\n",
       " 24,\n",
       " 25,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 22,\n",
       " 23,\n",
       " 25,\n",
       " 26,\n",
       " 24,\n",
       " 25,\n",
       " 24,\n",
       " 24,\n",
       " 23,\n",
       " 23,\n",
       " 24,\n",
       " 22,\n",
       " 23,\n",
       " 22,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 13,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 13,\n",
       " 11,\n",
       " 11,\n",
       " 10,\n",
       " 9,\n",
       " 10,\n",
       " 10,\n",
       " 12,\n",
       " 15,\n",
       " 15,\n",
       " 20,\n",
       " 21,\n",
       " 23,\n",
       " 21,\n",
       " 21,\n",
       " 20,\n",
       " 19,\n",
       " 14,\n",
       " 15,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 11,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 12,\n",
       " 10,\n",
       " 9,\n",
       " 11,\n",
       " 15,\n",
       " 16,\n",
       " 16,\n",
       " 17,\n",
       " 16,\n",
       " 17,\n",
       " 17,\n",
       " 14,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 10,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "last_vis_obj_i=[]   #contains number of visible obj in each sequence of the training\n",
    "\n",
    "for idx in range(len(adj)): \n",
    "    for i in range(len(adj[idx])): \n",
    "        if adj[idx][i,i] == 0:\n",
    "            last_vis_obj_i.append(i)\n",
    "            break   \n",
    "            \n",
    "last_vis_obj_i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "graph=dgl.DGLGraph(spp.coo_matrix(adj[0][:last_vis_obj_i[0],:last_vis_obj_i[0]]))\n",
    "graph=dgl.remove_self_loop(graph)\n",
    "print(graph.edges())\n",
    "nx.draw(graph.to_networkx(), with_labels=True)\n",
    "plt.show()\n",
    "print(graph.in_degrees(3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n",
      "tensor(1)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(4)\n",
      "tensor(5)\n",
      "tensor(6)\n",
      "tensor(7)\n",
      "tensor(8)\n",
      "tensor(9)\n",
      "tensor(10)\n",
      "tensor(11)\n",
      "tensor(12)\n"
     ]
    }
   ],
   "source": [
    "for n in graph.nodes():\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_dpi_ratio', { dpi_ratio: fig.ratio });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "    if (this.ratio !== 1) {\n",
       "        fig.send_message('set_dpi_ratio', { dpi_ratio: this.ratio });\n",
       "    }\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    var resizeObserver = new ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    resizeObserver.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch (cursor) {\n",
       "        case 0:\n",
       "            cursor = 'pointer';\n",
       "            break;\n",
       "        case 1:\n",
       "            cursor = 'default';\n",
       "            break;\n",
       "        case 2:\n",
       "            cursor = 'crosshair';\n",
       "            break;\n",
       "        case 3:\n",
       "            cursor = 'move';\n",
       "            break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = 'image/png';\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * this.ratio;\n",
       "    var y = canvas_pos.y * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.which === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.which;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which !== 17) {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    if (event.altKey && event.which !== 18) {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    if (event.shiftKey && event.which !== 16) {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data']);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.one(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager) {\n",
       "        manager = IPython.keyboard_manager;\n",
       "    }\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"639.8333333333334\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "graph=dgl.DGLGraph(spp.coo_matrix(adj[1][:last_vis_obj[1],:last_vis_obj[1]]))\n",
    "nx.draw(graph.to_networkx(), with_labels=True)\n",
    "plt.subplot(1,2,2)\n",
    "graph=dgl.DGLGraph(spp.coo_matrix(adj[2][:last_vis_obj[2],:last_vis_obj[2]]))\n",
    "nx.draw(graph.to_networkx(), with_labels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREPROCESS DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear grafo (Ejemplo secuencia 0)\n",
    "Para el entrenamiento iterar sobre todas las secuencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "now_history_frame=6\n",
    "object_type = features[:,:,:,2].int()  # torch Tensor NxVxT\n",
    "#vis_obj_type=np.zeros((features.shape[0],features.shape[1])) #NxV\n",
    "mask_car=np.zeros((features.shape[0],features.shape[1],now_history_frame)) #NxVx6\n",
    "for i in range(len(features)):\n",
    "    #vis_obj_type[i,:] =object_type[i,:,5] #Append Vx1 #tipos de obj visibles de la primera seq    \n",
    "    mask_car_t=np.array([1  if (j==2 or j==1) else 0 for j in object_type[i,:,5]])  #1 si obj 1/2 en frame 5 (size V)\n",
    "    mask_car[i,:]=np.array(mask_car_t).reshape(mask_car.shape[1],1)+np.zeros(6) #Vx6 mask para los 6 output frames que indican si el obj es visible y car\n",
    "\n",
    "#COMPROBADO OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([415, 70, 0, 2])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (415,70,0) (415,70,6) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-295-8407b478a45f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnode_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mmask_car\u001b[0m   \u001b[0;31m#Pongo 0 en feat 11 [mask] a todos los obj visibles no-car\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mnode_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mmask_car\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0moutput_mask\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmask_car\u001b[0m \u001b[0;31m#mascara obj (car) visibles en 6º frame (5010,120,6)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0moutput_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m#N,V,T,1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (415,70,0) (415,70,6) "
     ]
    }
   ],
   "source": [
    "\n",
    "feature_id = [3, 4, 9]  #x,y,heading,[visible_mask]\n",
    "#120 agentes (13 visibles -> feat[11]=1) y 12 frames (si no hay info en alguno de os 12 frames: fila nula)\n",
    "node_features = features[:,:,:now_history_frame,feature_id]  #obj type,x,y 6 primeros frames\n",
    "node_labels=features[:,:,now_history_frame:,3:5] #x,y 6 ultimos frames\n",
    "node_features[:,:,:,-1] *= mask_car   #Pongo 0 en feat 11 [mask] a todos los obj visibles no-car\n",
    "print(node_labels.shape)\n",
    "node_labels[:,:,:,-1] *= mask_car\n",
    "output_mask= features[:,:,6:,-1]*mask_car #mascara obj (car) visibles en 6º frame (5010,120,6)\n",
    "output_mask.unsqueeze_(-1).type(torch.uint8)    #N,V,T,1                  \n",
    "\n",
    "print(node_features.shape, node_labels.shape,output_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[51,\n",
       " 165,\n",
       " 166,\n",
       " 167,\n",
       " 168,\n",
       " 169,\n",
       " 170,\n",
       " 171,\n",
       " 172,\n",
       " 173,\n",
       " 174,\n",
       " 175,\n",
       " 176,\n",
       " 256,\n",
       " 257,\n",
       " 258,\n",
       " 259,\n",
       " 260,\n",
       " 261,\n",
       " 262,\n",
       " 263,\n",
       " 264,\n",
       " 265,\n",
       " 266,\n",
       " 267,\n",
       " 268,\n",
       " 269,\n",
       " 275,\n",
       " 276,\n",
       " 277,\n",
       " 278,\n",
       " 279,\n",
       " 280,\n",
       " 281,\n",
       " 282,\n",
       " 283,\n",
       " 284,\n",
       " 285,\n",
       " 286,\n",
       " 288,\n",
       " 289,\n",
       " 290,\n",
       " 298,\n",
       " 299,\n",
       " 300,\n",
       " 301,\n",
       " 311,\n",
       " 312,\n",
       " 314,\n",
       " 315,\n",
       " 316,\n",
       " 317,\n",
       " 318,\n",
       " 319,\n",
       " 320,\n",
       " 326,\n",
       " 327,\n",
       " 328,\n",
       " 329,\n",
       " 330,\n",
       " 331,\n",
       " 332,\n",
       " 333,\n",
       " 334,\n",
       " 335,\n",
       " 336,\n",
       " 337,\n",
       " 338,\n",
       " 339,\n",
       " 340,\n",
       " 341,\n",
       " 342,\n",
       " 343,\n",
       " 344,\n",
       " 345,\n",
       " 346,\n",
       " 347,\n",
       " 348,\n",
       " 349,\n",
       " 350,\n",
       " 351,\n",
       " 352,\n",
       " 353,\n",
       " 354,\n",
       " 355,\n",
       " 356,\n",
       " 357,\n",
       " 358,\n",
       " 359,\n",
       " 363,\n",
       " 364,\n",
       " 365,\n",
       " 366,\n",
       " 1104,\n",
       " 1105,\n",
       " 1106,\n",
       " 1107,\n",
       " 1108,\n",
       " 1109,\n",
       " 1110,\n",
       " 1111,\n",
       " 1112,\n",
       " 1113,\n",
       " 1114,\n",
       " 1115,\n",
       " 1116,\n",
       " 1117,\n",
       " 1118,\n",
       " 1119,\n",
       " 1191,\n",
       " 1192,\n",
       " 1193,\n",
       " 1194,\n",
       " 1195,\n",
       " 1196,\n",
       " 1197,\n",
       " 1198,\n",
       " 1199,\n",
       " 1200,\n",
       " 1201,\n",
       " 1202,\n",
       " 1203,\n",
       " 1204,\n",
       " 1205,\n",
       " 1206,\n",
       " 1207,\n",
       " 1208,\n",
       " 1209,\n",
       " 1210,\n",
       " 1211,\n",
       " 1212,\n",
       " 1213,\n",
       " 1214,\n",
       " 1215,\n",
       " 1216,\n",
       " 1217,\n",
       " 1218,\n",
       " 1219,\n",
       " 1220,\n",
       " 1221,\n",
       " 1222,\n",
       " 1223,\n",
       " 1224,\n",
       " 1225,\n",
       " 1226,\n",
       " 1227,\n",
       " 1231,\n",
       " 1232,\n",
       " 1233,\n",
       " 1244,\n",
       " 1245,\n",
       " 1246,\n",
       " 1247,\n",
       " 1248,\n",
       " 1249,\n",
       " 1270,\n",
       " 1419,\n",
       " 1420,\n",
       " 1421,\n",
       " 1422,\n",
       " 1423,\n",
       " 1424,\n",
       " 1425,\n",
       " 1426,\n",
       " 1427,\n",
       " 1428,\n",
       " 1429,\n",
       " 1437,\n",
       " 1438,\n",
       " 1439,\n",
       " 1440,\n",
       " 1441,\n",
       " 1442,\n",
       " 1443,\n",
       " 1444,\n",
       " 1445,\n",
       " 1446,\n",
       " 1476,\n",
       " 1494,\n",
       " 1495,\n",
       " 1496,\n",
       " 1497,\n",
       " 1498,\n",
       " 1499,\n",
       " 1605,\n",
       " 1667,\n",
       " 1668,\n",
       " 1669,\n",
       " 1670,\n",
       " 1671,\n",
       " 1672,\n",
       " 1673,\n",
       " 1674,\n",
       " 1675,\n",
       " 1676,\n",
       " 1677,\n",
       " 1678,\n",
       " 1679,\n",
       " 1680,\n",
       " 1681,\n",
       " 1682,\n",
       " 1683,\n",
       " 1684,\n",
       " 1685,\n",
       " 1686,\n",
       " 1687,\n",
       " 1688,\n",
       " 1689,\n",
       " 1690,\n",
       " 1691,\n",
       " 1692,\n",
       " 1693,\n",
       " 1694,\n",
       " 1695,\n",
       " 1696,\n",
       " 1882,\n",
       " 1893,\n",
       " 1894,\n",
       " 1895,\n",
       " 1896,\n",
       " 1897,\n",
       " 1898,\n",
       " 1899,\n",
       " 1900,\n",
       " 1901,\n",
       " 1902,\n",
       " 1903,\n",
       " 1904,\n",
       " 1905,\n",
       " 1906,\n",
       " 1907,\n",
       " 1908,\n",
       " 1909,\n",
       " 1910,\n",
       " 2181,\n",
       " 2182,\n",
       " 2183,\n",
       " 2184,\n",
       " 2674,\n",
       " 2675,\n",
       " 2676,\n",
       " 2677,\n",
       " 2678,\n",
       " 2679,\n",
       " 2680,\n",
       " 2681,\n",
       " 2682,\n",
       " 2683,\n",
       " 2684,\n",
       " 2685,\n",
       " 2686,\n",
       " 2687,\n",
       " 2688,\n",
       " 2689,\n",
       " 2690,\n",
       " 2691,\n",
       " 2692,\n",
       " 2693,\n",
       " 2694,\n",
       " 2695,\n",
       " 2696,\n",
       " 2697,\n",
       " 2698,\n",
       " 2745,\n",
       " 2969,\n",
       " 2970,\n",
       " 2971,\n",
       " 2972,\n",
       " 3329,\n",
       " 3330,\n",
       " 3331,\n",
       " 3332,\n",
       " 3333,\n",
       " 3334,\n",
       " 3335,\n",
       " 3417,\n",
       " 3418,\n",
       " 3419,\n",
       " 3420,\n",
       " 3421,\n",
       " 3422,\n",
       " 3423,\n",
       " 3424,\n",
       " 3445,\n",
       " 3446,\n",
       " 3447,\n",
       " 3448,\n",
       " 3449,\n",
       " 3450,\n",
       " 3451,\n",
       " 3452,\n",
       " 3631,\n",
       " 3632,\n",
       " 3633,\n",
       " 3634,\n",
       " 3635,\n",
       " 3636,\n",
       " 3704,\n",
       " 3705,\n",
       " 3706,\n",
       " 3707,\n",
       " 3708,\n",
       " 3709,\n",
       " 3710,\n",
       " 3711,\n",
       " 3712,\n",
       " 3713,\n",
       " 3714,\n",
       " 3715,\n",
       " 3716,\n",
       " 3717,\n",
       " 3718,\n",
       " 3719,\n",
       " 3720,\n",
       " 3721,\n",
       " 3722,\n",
       " 3756,\n",
       " 3757,\n",
       " 3758,\n",
       " 3759,\n",
       " 3760,\n",
       " 3761,\n",
       " 3762,\n",
       " 3763,\n",
       " 3764,\n",
       " 3765,\n",
       " 3766,\n",
       " 3767,\n",
       " 3768,\n",
       " 3769,\n",
       " 3770,\n",
       " 3771,\n",
       " 3772,\n",
       " 3773,\n",
       " 3774,\n",
       " 3775,\n",
       " 3776,\n",
       " 3777,\n",
       " 3778,\n",
       " 3779,\n",
       " 3780,\n",
       " 3781,\n",
       " 3782,\n",
       " 3783,\n",
       " 3784,\n",
       " 3785,\n",
       " 3786,\n",
       " 3787,\n",
       " 3788,\n",
       " 3789,\n",
       " 3790,\n",
       " 3791,\n",
       " 3792,\n",
       " 3793,\n",
       " 3794,\n",
       " 3795,\n",
       " 3796,\n",
       " 3797,\n",
       " 3798,\n",
       " 3906,\n",
       " 3907,\n",
       " 3908,\n",
       " 3909,\n",
       " 3910,\n",
       " 3911,\n",
       " 3912,\n",
       " 3913,\n",
       " 3914,\n",
       " 4443,\n",
       " 4444,\n",
       " 4445,\n",
       " 4446,\n",
       " 4447,\n",
       " 4448,\n",
       " 4449,\n",
       " 4450,\n",
       " 4451,\n",
       " 4452,\n",
       " 4453,\n",
       " 4454,\n",
       " 4455,\n",
       " 4459,\n",
       " 4479,\n",
       " 4480,\n",
       " 4481,\n",
       " 4482,\n",
       " 4483,\n",
       " 4484,\n",
       " 4485,\n",
       " 4526,\n",
       " 4788,\n",
       " 4789,\n",
       " 4790,\n",
       " 4791,\n",
       " 4792,\n",
       " 4793,\n",
       " 4794,\n",
       " 4795,\n",
       " 4796,\n",
       " 4800,\n",
       " 4801,\n",
       " 4802,\n",
       " 4803,\n",
       " 4804,\n",
       " 4805,\n",
       " 4806,\n",
       " 4807,\n",
       " 4808,\n",
       " 4809,\n",
       " 4810,\n",
       " 4811,\n",
       " 4906,\n",
       " 4907,\n",
       " 4917]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_indeces_list = [i for i in range(len(output_mask)) if np.all(np.array(output_mask.squeeze(-1))==0, axis=(1,2))[i] == True ]\n",
    "zero_indeces_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "374"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_maskcar_list = [i for i in range(len(mask_car)) if np.all(np.array(mask_car)==0, axis=(1,2))[i] == True ]\n",
    "len(zero_maskcar_list) #374"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3677\n"
     ]
    }
   ],
   "source": [
    "total_num = len(features)\n",
    "id_list = list(set(list(range(total_num))) - set(zero_indeces_list))\n",
    "total_valid_num = len(id_list) #4596\n",
    "ind=np.random.permutation(id_list)\n",
    "train_id_list, val_id_list = ind[:round(total_valid_num*0.8)], ind[round(total_valid_num*0.8):]\n",
    "\n",
    "\n",
    "'''\n",
    "train_id_list = list(np.linspace(0, total_valid_num-1, int(total_valid_num*0.8)).astype(int))\n",
    "val_id_list = list(set(list(range(total_valid_num))) - set(train_id_list))  \n",
    "\n",
    "if train_val_test.lower() == 'train':\n",
    "    self.all_feature = self.all_feature[train_id_list]\n",
    "    self.all_adjacency = self.all_adjacency[train_id_list]\n",
    "    self.all_mean_xy = self.all_mean_xy[train_id_list]\n",
    "elif train_val_test.lower() == 'val':\n",
    "    self.all_feature = self.all_feature[val_id_list]\n",
    "    self.all_adjacency = self.all_adjacency[val_id_list]\n",
    "    self.all_mean_xy = self.all_mean_xy[val_id_list]\n",
    "'''\n",
    "print(len(train_id_list)) #3677"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_dist=[spatial.distance.cdist(node_features[i][:,5,:], node_features[i][:,5,:]) for i in range(len(features))]  #5010x120x120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####PESOS EN EDGES\n",
    "#120x120 -> solo quiero los que tengan 1 en Adj[0] (máscara) aka 39 valores\n",
    "#Obtener las 39 distancias correspondientes a cada edge\n",
    "distances = [xy_dist[0][graph.edges()[0][i]][graph.edges()[1][i]] for i in range(graph.num_edges())]\n",
    "print(len(distances))\n",
    "norm_distances = [(i-min(distances))/(max(distances)-min(distances)) for i in distances]\n",
    "norm_distances = [1/(i) if i!=0 else 1 for i in distances]\n",
    "print(norm_distances)\n",
    "#NORMALIZAR ENTRE 0 Y 1\n",
    "graph.edata['w']=torch.tensor(norm_distances, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl.function as fn\n",
    "#Perform message passing and then apply fc Layer (self-loops! - same W for neighbors and itself)\n",
    "# Traditional GCN:\n",
    "#fn.copy_src(src='h', out='m')\n",
    "#gcn_reduce = fn.sum(msg='m', out='h')\n",
    "# multiply source node features with edge weights and aggregate them in destination nodes\n",
    "gcn_msg=fn.u_mul_e('h', 'w', 'm') #elemnt-wise (broadcast)\n",
    "gcn_reduce = fn.sum(msg='m', out='h')\n",
    "class GCNLayer(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats):\n",
    "        super(GCNLayer, self).__init__()\n",
    "        self.linear_self = nn.Linear(in_feats, out_feats, bias=False)\n",
    "        self.linear = nn.Linear(in_feats, out_feats)\n",
    "        \n",
    "    def reduce_func(self, nodes):\n",
    "        h = torch.sum(nodes.mailbox['m'], dim=1)\n",
    "        return {'h': h}\n",
    "\n",
    "    def forward(self, g, feature,e_w, snorm_n, snorm_e):\n",
    "        # Creating a local scope so that all the stored ndata and edata\n",
    "        # (such as the `'h'` ndata below) are automatically popped out\n",
    "        # when the scope exits.\n",
    "        with g.local_scope():\n",
    "            \n",
    "            g.ndata['h_s']=self.linear_self(feature)\n",
    "            \n",
    "            #normalization\n",
    "            degs = g.out_degrees().float().clamp(min=1)\n",
    "            norm=torch.pow(degs,-0.5)\n",
    "            shp = norm.shape + (1,)*(feature.dim() -1)\n",
    "            norm = torch.reshape(norm,shp)\n",
    "            feature = feature*norm\n",
    "            \n",
    "            #aggregate\n",
    "            g.edata['w'] = e_w\n",
    "            g.ndata['h'] = feature\n",
    "            g.update_all(gcn_msg, self.reduce_func)\n",
    "            \n",
    "            #mult W and normalization\n",
    "            h = self.linear(g.ndata['h'])\n",
    "            degs = g.in_degrees().float().clamp(min=1)\n",
    "            norm = torch.pow(degs, -0.5)\n",
    "            shp = norm.shape + (1,) * (feature.dim() - 1)\n",
    "            norm = torch.reshape(norm, shp)\n",
    "            h = h * norm\n",
    "            \n",
    "            h = g.ndata['h_s'] + h #Vx6xout_feats\n",
    "            \n",
    "            #h = h * (torch.ones_like(h)*snorm_n)  # normalize activation w.r.t. graph node size\n",
    "            #e_w =  e_w * (torch.ones_like(e_w)*snorm_e)  # normalize activation w.r.t. graph edge size\n",
    "            e_w =  e_w\n",
    "            \n",
    "            return h, e_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prueba forward pass en gcn con un grafo OK\n",
    "#model = GCN(in_feats=4, hid_feats=64, out_feats=2)\n",
    "#model(graph, graph.ndata['x'],graph.edata['w'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([70, 6, 2])\n"
     ]
    }
   ],
   "source": [
    "from dgl.nn import GatedGraphConv, GraphConv, GATConv,SAGEConv\n",
    "\n",
    "conv = GraphConv(4,2, weight=True, bias=True)\n",
    "#sageconv = SAGEConv(4,2,aggregator_type='lstm')\n",
    "#gated_conv = GatedGraphConv(4, 2, 2, 3)\n",
    "#gatconv=GATConv(4,2,num_heads=4)\n",
    "graph = dgl.add_self_loop(graph)   #Añado selfloops pq no puede haber zero in-degree nodes\n",
    "res = conv(graph, node_features[0])\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Convolutional Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, hid_feats, out_feats):\n",
    "        super().__init__()\n",
    "        self.embedding_h = nn.Linear(in_feats, hid_feats)\n",
    "        self.conv1 = GCNLayer(in_feats=hid_feats, out_feats=hid_feats)\n",
    "        self.conv2 = GCNLayer(in_feats=hid_feats, out_feats=hid_feats)\n",
    "        self.fc= nn.Linear(hid_feats,out_feats)\n",
    "    def forward(self, graph, inputs,e_w,snorm_n, snorm_e):\n",
    "        # input embedding\n",
    "        h = self.embedding_h(inputs)\n",
    "        h,e_w = self.conv1(graph, h,e_w,snorm_n, snorm_e) #Vx6x4 -> Vx6x32  \n",
    "        h = F.relu(h)\n",
    "        h,_ = self.conv2(graph,h,e_w,snorm_n, snorm_e)  #Vx6x2 \n",
    "        h = F.relu(h)\n",
    "        y = self.fc(h)\n",
    "        return y\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAT Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_GATLayer(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats):\n",
    "        super(My_GATLayer, self).__init__()\n",
    "        self.linear_self = nn.Linear(in_feats, out_feats, bias=False)\n",
    "        self.linear_func = nn.Linear(in_feats, out_feats, bias=False)\n",
    "        self.attention_func = nn.Linear(2 * out_feats, 1, bias=False)\n",
    "        self.bn_node = nn.BatchNorm1d(out_feats)\n",
    "        \n",
    "    def edge_attention(self, edges):\n",
    "        concat_z = torch.cat([edges.src['z'], edges.dst['z']], dim=-1) #(n_edg,6*64)||(n_edg,6*64) -> (n_edg,2*6*64) \n",
    "        src_e = self.attention_func(concat_z)  #(n_edg, 1) att logit\n",
    "        src_e = F.leaky_relu(src_e)\n",
    "        return {'e': src_e}\n",
    "    \n",
    "    def message_func(self, edges):\n",
    "        return {'z': edges.src['z'], 'e':edges.data['e']}\n",
    "        \n",
    "    def reduce_func(self, nodes):\n",
    "        h_s = nodes.data['h_s']\n",
    "        a = F.softmax(nodes.mailbox['e'], dim=1)   #attention score between nodes i and j\n",
    "        h = h_s + torch.sum(a * nodes.mailbox['z'], dim=1)\n",
    "        return {'h': h}\n",
    "                               \n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            h_in = h\n",
    "            g.ndata['h']  = h \n",
    "            g.ndata['h_s'] = self.linear_self(h) \n",
    "            g.ndata['z'] = self.linear_func(h) #(18) -> (18) \n",
    "            g.apply_edges(self.edge_attention)\n",
    "            g.update_all(self.message_func, self.reduce_func)\n",
    "            h = g.ndata['h'] # result of graph convolution\n",
    "            #h = h * snorm_n # normalize activation w.r.t. graph node size\n",
    "            h = self.bn_node(h) # batch normalization \n",
    "            \n",
    "            h = torch.relu(h) # non-linear activation\n",
    "            h = h_in + h # residual connection\n",
    "            \n",
    "            return h #graph.ndata.pop('h')\n",
    "\n",
    "\n",
    "class MultiHeadGATLayer(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats, num_heads, merge='cat'):\n",
    "        super(MultiHeadGATLayer, self).__init__()\n",
    "        self.heads = nn.ModuleList()\n",
    "        for i in range(num_heads):\n",
    "            self.heads.append(My_GATLayer(in_feats, out_feats))\n",
    "        self.merge = merge\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        head_outs = [attn_head(g, h) for attn_head in self.heads]\n",
    "        if self.merge == 'cat':\n",
    "            # concat on the output feature dimension (dim=1), for intermediate layers\n",
    "            return torch.cat(head_outs, dim=1)\n",
    "        else:\n",
    "            # merge using average, for final layer\n",
    "            return torch.mean(torch.stack(head_outs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_layer(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, input_dim/2) \n",
    "        self.layer2 = nn.Linear(input_dim/2, input_dim/4) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = x\n",
    "        y = self.layer1(y)\n",
    "        y = torch.relu(y)\n",
    "        y = self.layer2(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My_GAT(\n",
      "  (embedding_h): Linear(in_features=18, out_features=128, bias=True)\n",
      "  (gat_1): My_GATLayer(\n",
      "    (linear_self): Linear(in_features=128, out_features=128, bias=False)\n",
      "    (linear_func): Linear(in_features=128, out_features=128, bias=False)\n",
      "    (attention_func): Linear(in_features=256, out_features=1, bias=False)\n",
      "    (bn_node): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (gat_2): My_GATLayer(\n",
      "    (linear_self): Linear(in_features=128, out_features=128, bias=False)\n",
      "    (linear_func): Linear(in_features=128, out_features=128, bias=False)\n",
      "    (attention_func): Linear(in_features=256, out_features=1, bias=False)\n",
      "    (bn_node): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (linear1): Linear(in_features=128, out_features=12, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class My_GAT(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, heads=4):\n",
    "        super().__init__()\n",
    "        self.embedding_h = nn.Linear(input_dim, hidden_dim)\n",
    "        self.gat_1 = My_GATLayer(hidden_dim, hidden_dim)\n",
    "        self.gat_2 = My_GATLayer(hidden_dim, hidden_dim)\n",
    "        #self.gat_1 = MultiHeadGATLayer(hidden_dim, hidden_dim, heads)\n",
    "        #self.gat_2 = MultiHeadGATLayer(hidden_dim*heads, hidden_dim*heads, 1)\n",
    "        \n",
    "        self.linear1 = nn.Linear(hidden_dim, output_dim) #hidden*heads para multihead\n",
    "        #self.linear2 = nn.Linear( int(hidden_dim/2),  output_dim)\n",
    "        \n",
    "    def forward(self, g, h,e_w,snorm_n,snorm_e):\n",
    "        \n",
    "        # input embedding\n",
    "        h = self.embedding_h(h)  #input (70, 6,4) - (70, 6,32) checked\n",
    "        # gat layers\n",
    "        h = self.gat_1(g, h)\n",
    "        h = self.gat_2(g, h)\n",
    "        \n",
    "        y = self.linear1(h)  # (6,32) -> (6,2)\n",
    "        #y = self.linear2(torch.relu(y))\n",
    "        return y\n",
    "    \n",
    "print( My_GAT(input_dim=18, hidden_dim=128, output_dim=12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gated GCN \n",
    "$$\n",
    "\\def \\vx {\\boldsymbol{\\color{Plum}{x}}}\n",
    "\\def \\vh {\\boldsymbol{\\color{YellowGreen}{h}}}\n",
    "\\def \\ve {\\boldsymbol{\\color{purple}{e}}}\n",
    "\\def \\aqua#1{\\color{Aquamarine}{#1}}\n",
    "\\def \\red#1{\\color{OrangeRed}{#1}}\n",
    "$$\n",
    "\n",
    "\\begin{aligned}\n",
    "\\vh &= \\vx + \\Big( A \\vx +  \\sum_{\\aqua{v}_j \\to \\red{v}} \\eta(\\ve_{j}) \\odot B \\vx_j \\Big)^+\\\\\n",
    "\\eta(\\ve_{j}) &= \\sigma(\\ve_{j})\\Big(\\sum_{\\aqua{v}_k \\to \\red{v}} \\sigma(\\ve_{k})\\Big)^{-1} \\\\\n",
    "\\ve_{j} &= C \\ve_{j}^{\\vx} + D \\vx_j + E\\vx\\\\\n",
    "\\ve_{j}^{\\vh} &= \\ve_j^{\\vx} + \\Big( \\ve_{j}  \\Big)^+\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatedGCN_layer(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.A = nn.Linear(input_dim, output_dim)\n",
    "        self.B = nn.Linear(input_dim, output_dim)\n",
    "        self.C = nn.Linear(input_dim, output_dim)\n",
    "        self.D = nn.Linear(input_dim, output_dim)\n",
    "        self.E = nn.Linear(input_dim, output_dim)\n",
    "        self.bn_node_h = nn.BatchNorm1d(output_dim)\n",
    "        self.bn_node_e = nn.BatchNorm1d(output_dim)\n",
    "\n",
    "    def message_func(self, edges):\n",
    "        Bh_j = edges.src['Bh']\n",
    "        # e_ij = Ce_ij + Dhi + Ehj\n",
    "        e_ij = edges.data['Ce'] + edges.src['Dh'] + edges.dst['Eh']\n",
    "        edges.data['e'] = e_ij\n",
    "        return {'Bh_j' : Bh_j, 'e_ij' : e_ij}\n",
    "\n",
    "    def reduce_func(self, nodes):\n",
    "        Ah_i = nodes.data['Ah']\n",
    "        Bh_j = nodes.mailbox['Bh_j']\n",
    "        e = nodes.mailbox['e_ij']\n",
    "        # sigma_ij = sigmoid(e_ij)\n",
    "        sigma_ij = torch.sigmoid(e)\n",
    "        # hi = Ahi + sum_j eta_ij * Bhj\n",
    "        h = Ah_i + torch.sum(sigma_ij * Bh_j, dim=1) / torch.sum(sigma_ij, dim=1)\n",
    "        return {'h' : h}\n",
    "    \n",
    "    def forward(self, g, h, e, snorm_n, snorm_e):\n",
    "        \n",
    "        h_in = h # residual connection\n",
    "        e_in = e # residual connection\n",
    "        \n",
    "        g.ndata['h']  = h \n",
    "        g.ndata['Ah'] = self.A(h) \n",
    "        g.ndata['Bh'] = self.B(h) \n",
    "        g.ndata['Dh'] = self.D(h)\n",
    "        g.ndata['Eh'] = self.E(h) \n",
    "        g.edata['e']  = e \n",
    "        g.edata['Ce'] = self.C(e)\n",
    "        \n",
    "        g.update_all(self.message_func, self.reduce_func)\n",
    "        \n",
    "        h = g.ndata['h'] # result of graph convolution\n",
    "        e = g.edata['e'] # result of graph convolution\n",
    "\n",
    "        \n",
    "        #h = h * snorm_n # normalize activation w.r.t. graph node size\n",
    "        #e = e * snorm_e # normalize activation w.r.t. graph edge size\n",
    "        \n",
    "        h = self.bn_node_h(h) # batch normalization  \n",
    "        e = self.bn_node_e(e) # batch normalization  \n",
    "        \n",
    "        h = torch.relu(h) # non-linear activation\n",
    "        e = torch.relu(e) # non-linear activation\n",
    "        \n",
    "        h = h_in + h # residual connection\n",
    "        e = e_in + e # residual connection\n",
    "        \n",
    "        return h, e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GatedGCN(\n",
      "  (embedding_h): Linear(in_features=18, out_features=128, bias=True)\n",
      "  (embedding_e): Linear(in_features=1, out_features=128, bias=True)\n",
      "  (GatedGCN1): GatedGCN_layer(\n",
      "    (A): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (B): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (C): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (D): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (E): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (bn_node_h): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn_node_e): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (GatedGCN2): GatedGCN_layer(\n",
      "    (A): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (B): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (C): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (D): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (E): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (bn_node_h): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn_node_e): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (linear1): Linear(in_features=128, out_features=12, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class GatedGCN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.embedding_h = nn.Linear(input_dim, hidden_dim)\n",
    "        self.embedding_e = nn.Linear(1, hidden_dim)\n",
    "        self.GatedGCN1 = GatedGCN_layer(hidden_dim, hidden_dim)\n",
    "        self.GatedGCN2 = GatedGCN_layer(hidden_dim, hidden_dim)\n",
    "        self.linear1 = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, g, h, e, snorm_n, snorm_e):\n",
    "        # input embedding\n",
    "        h = self.embedding_h(h)\n",
    "        e = self.embedding_e(e)\n",
    "        # graph convnet layers\n",
    "        h, e = self.GatedGCN1(g, h, e, snorm_n, snorm_e)\n",
    "        h, e = self.GatedGCN2(g, h, e, snorm_n, snorm_e)\n",
    "        # MLP \n",
    "        y = self.linear1(h)\n",
    "        \n",
    "        return y\n",
    "\n",
    "print( GatedGCN(input_dim=18, hidden_dim=128, output_dim=12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train one epoch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/54 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/54 [00:00<00:19,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(834.7400, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 2/54 [00:00<00:18,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/54 [00:01<00:18,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 4/54 [00:01<00:17,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 5/54 [00:01<00:18,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 6/54 [00:02<00:19,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 7/54 [00:02<00:18,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 8/54 [00:02<00:16,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 9/54 [00:03<00:16,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 10/54 [00:03<00:18,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 11/54 [00:04<00:17,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 11/54 [00:04<00:17,  2.45it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-4e1f40e0f904>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0moverall_loss_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_graphs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_snorm_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_snorm_e\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvis\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_graphs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mfeats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1165\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1166\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PROGRAMAS/DBU_Graph/ApolloScape_Dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m#graph = dgl.add_self_loop(graph)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxy_dist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0mnorm_distances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdistances\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mnorm_distances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdistances\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PROGRAMAS/DBU_Graph/ApolloScape_Dataset.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m#graph = dgl.add_self_loop(graph)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxy_dist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0mnorm_distances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdistances\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mnorm_distances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdistances\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#train_iter=iter(train_dataloader)\n",
    "\n",
    "def val(model, val_dataloader,val_loss_sum):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        overall_num_list=[] \n",
    "        overall_x2y2_list=[]\n",
    "        for batched_graph, output_masks,snorm_n, snorm_e,last_vis_obj in tqdm(val_dataloader):\n",
    "            feats = batched_graph.ndata['x'].float().to(dev)\n",
    "            #reshape to have shape (B*V,T*C) [c1,c2,...,c6]\n",
    "            feats = feats.view(feats.shape[0],-1)\n",
    "            e_w = batched_graph.edata['w'].float().to(dev)\n",
    "            \n",
    "            #for GatedGCN\n",
    "            e_w= e_w.view(e_w.shape[0],1)\n",
    "            \n",
    "            labels= batched_graph.ndata['gt'][:,:,:].float().to(dev)\n",
    "            #labels = labels.view(labels.shape[0], -1)\n",
    "            pred = model(batched_graph, feats,e_w,snorm_n,snorm_e)\n",
    "            _, overall_num, x2y2_error = compute_RMSE_batch(pred, labels, output_masks[:,:,:])\n",
    "            #print(x2y2_error.shape)  #BV,T\n",
    "            overall_num_list.extend(overall_num.detach().cpu().numpy())\n",
    "            #print(overall_num.shape)  #BV,T\n",
    "            overall_x2y2_list.extend((x2y2_error**0.5).detach().cpu().numpy())  #RMSE para cada nodo en cada T\n",
    "            \n",
    "    overall_sum_time=np.sum(overall_x2y2_list,axis=0)  #BV,T->T RMSE medio en cada T\n",
    "    overall_num_time =np.sum(overall_num_list, axis=0)\n",
    "    overall_loss_time=(overall_sum_time / overall_num_time) #media del error de cada agente en cada frame\n",
    "\n",
    "    print('|{}| Val_loss: {}'.format(datetime.now(), ' '.join(['{:.3f}'.format(x) for x in list(overall_loss_time) + [np.sum(overall_loss_time)]])))\n",
    "    val_loss_sum.append(np.sum(overall_loss_time))\n",
    "\n",
    "model = GatedGCN(input_dim=18, hidden_dim=256, output_dim=12).to(dev)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "train_loss_sum=[]\n",
    "val_loss_sum=[]\n",
    "val_loss_prev=0\n",
    "for epoch in range(20):\n",
    "    print(\"Epoch: \",epoch)\n",
    "    overall_loss_train=[]\n",
    "    model.train()\n",
    "    for batch_graphs, masks, batch_snorm_n, batch_snorm_e, vis in tqdm(train_dataloader):\n",
    "        feats = batch_graphs.ndata['x'].float().to(dev)\n",
    "        feats=feats.view(feats.shape[0],-1)\n",
    "        batch_e = batch_graphs.edata['w'].float().to(dev)\n",
    "        batch_e=batch_e.view(batch_e.shape[0],1)\n",
    "\n",
    "        #model = GatedGCN(input_dim=18, hidden_dim=256, output_dim=12).to(dev)\n",
    "        batch_pred = model(batch_graphs, feats, batch_e, batch_snorm_n, batch_snorm_e)\n",
    "        #print(batch_pred.shape, masks.shape)\n",
    "\n",
    "        labels= batch_graphs.ndata['gt'].float().to(dev)\n",
    "        overall_sum_time, overall_num, _ = compute_RMSE_batch(batch_pred, labels, masks)  #(B,6)\n",
    "        total_loss=torch.sum(overall_sum_time)/torch.sum(overall_num.sum(dim=-2))\n",
    "        print(total_loss)\n",
    "        opt.zero_grad() \n",
    "        total_loss.backward()\n",
    "        opt.step()\n",
    "        overall_loss_train.extend([total_loss.data.item()])\n",
    "    print('|{}| Train_loss: {}'.format(datetime.now(), np.sum(overall_loss_train)/len(overall_loss_train)))\n",
    "    train_loss_sum.append(np.sum(overall_loss_train)/len(overall_loss_train))\n",
    "    val(model, val_dataloader, val_loss_sum)\n",
    "    if val_loss_prev < val_loss_sum[-1] and epoch !=0:\n",
    "        patience+=1\n",
    "        val_loss_prev = val_loss_sum[-1]\n",
    "    else:\n",
    "        patience = 0\n",
    "        val_loss_prev = val_loss_sum[-1]\n",
    "    if patience > 2:\n",
    "        print(\"Early stopping: \")\n",
    "        print(\"Difference: {}\".format(val_loss_prev-val_loss_sum[-1]))\n",
    "        break\n",
    "\n",
    "print('Val loss sum: {}'.format(val_loss_sum))\n",
    "epochs = list(range(epoch+1))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epochs,train_loss_sum)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Train Loss')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epochs,val_loss_sum)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Val Loss')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collate function to prepare graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_RMSE_batch(pred, gt, mask): \n",
    "    #output mask vale 0 si no visible o no-car o visible pero no hay datos en ese frame  (B*V,T,1), cada fila un nodo de un grafo perteneciente al batch\n",
    "    pred=pred.view(pred.shape[0],mask.shape[1],-1)\n",
    "    #gt=gt.view(pred.shape[0],6,-1)\n",
    "    \n",
    "    pred = pred*mask #B*V,T,C  (B n grafos en el batch)\n",
    "    gt = gt*mask  # outputmask BV,T,C\n",
    "    \n",
    "    x2y2_error=torch.sum(torch.abs(pred-gt)**2,dim=-1) # x^2+y^2 BV,T\n",
    "    overall_sum_time = x2y2_error.sum(dim=-2)  #T - suma de los errores (x^2+y^2) de los V agentes\n",
    "    overall_num = mask.sum(dim=-1).type(torch.int)  #torch.Tensor[(T)] - num de agentes (Y CON DATOS) en cada frame\n",
    "    return overall_sum_time, overall_num, x2y2_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collate function to prepare graphs\n",
    "def collate(graph):\n",
    "    snorm_n = (1 / graph.number_of_nodes())**0.5  # graph size normalization \n",
    "    snorm_e = (1 / graph.number_of_edges())**0.5 # graph size normalization\n",
    "    norm_d = torch.pow(graph.in_degrees().float(),-0.5)\n",
    "    norm_d[torch.isinf(norm_d)]=0  #size [n_nodes]\n",
    "    return snorm_n, snorm_e, norm_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/54 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/54 [00:01<00:54,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5.2494e+00,  2.7833e-01, -2.2304e+00,  ..., -1.3503e+00,\n",
      "         -8.9911e+00, -2.0562e+00],\n",
      "        [-9.0951e+00,  1.6989e+00,  6.2031e+00,  ...,  6.2522e-01,\n",
      "          2.0554e+01,  6.7654e+00],\n",
      "        [-6.0123e-01,  7.3570e-01,  5.4569e-01,  ...,  7.3439e-01,\n",
      "          1.0325e+00,  3.0541e-01],\n",
      "        ...,\n",
      "        [-1.4271e+00, -1.3944e+00, -1.2644e+00,  ..., -7.1814e-03,\n",
      "          6.0467e-02,  8.9451e-01],\n",
      "        [-1.6194e+00, -1.5305e+00, -1.3849e+00,  ..., -1.0530e-01,\n",
      "          4.5729e-02,  9.8453e-01],\n",
      "        [ 7.5676e+00,  3.1102e+00,  4.7571e+00,  ...,  9.4652e+00,\n",
      "          3.8125e+00, -4.4283e+00]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 2/54 [00:01<00:42,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/54 [00:01<00:34,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 4/54 [00:02<00:29,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 5/54 [00:02<00:26,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 6/54 [00:02<00:24,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 7/54 [00:03<00:21,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 8/54 [00:03<00:18,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 9/54 [00:03<00:17,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 10/54 [00:04<00:18,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 10/54 [00:04<00:20,  2.11it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b5dd2c8716ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0moverall_loss_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatched_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_masks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msnorm_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msnorm_e\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlast_vis_obj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatched_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m#reshape to have shape (B*V,T*C) [c1,c2,...,c6]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1165\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1166\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PROGRAMAS/DBU_Graph/ApolloScape_Dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_degrees\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                 \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m#graph = dgl.add_self_loop(graph)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/dgl/heterograph.py\u001b[0m in \u001b[0;36madd_edges\u001b[0;34m(self, u, v, data, etype)\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0metid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_etype_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_edge_frames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0metid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_rows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_edge_frames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0metid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/usuario1/miniconda3/envs/pDL/lib/python3.8/site-packages/dgl/frame.py\u001b[0m in \u001b[0;36madd_rows\u001b[0;34m(self, num_rows)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_columns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheme\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0madd_rows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \"\"\"Add blank rows to this frame.\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "dev='cuda'\n",
    "#model = GCN(in_feats=18, hid_feats=256, out_feats=12).to(dev)\n",
    "model = GatedGCN(input_dim=18, hidden_dim=128, output_dim=12).to(dev)\n",
    "#model = My_GAT(input_dim=18, hidden_dim=256, output_dim=12).to(dev)\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "np.seterr(all='raise')\n",
    "train_loss_sum=[]\n",
    "val_loss_sum=[]\n",
    "val_loss_prev=0\n",
    "patience=0\n",
    "for epoch in range(50):\n",
    "    print('Epoch: ',epoch)\n",
    "    overall_loss_train=[]\n",
    "    model.train()\n",
    "    for batched_graph, output_masks,snorm_n, snorm_e,last_vis_obj in tqdm(train_dataloader):\n",
    "        feats = batched_graph.ndata['x'].float().to(dev)\n",
    "        #reshape to have shape (B*V,T*C) [c1,c2,...,c6]\n",
    "        feats = feats.view(feats.shape[0],-1)\n",
    "        e_w = batched_graph.edata['w'].float().to(dev)\n",
    "        \n",
    "        #for GatedGCN\n",
    "        e_w= e_w.view(e_w.shape[0],1)\n",
    "        \n",
    "        labels= batched_graph.ndata['gt'].float().to(dev)\n",
    "        pred = model(batched_graph, feats,e_w,snorm_n,snorm_e)   #70,6,2\n",
    "        overall_sum_time, overall_num, _ = compute_RMSE_batch(pred, labels, output_masks)  #(B,6)\n",
    "        print(pred)\n",
    "        total_loss=torch.sum(overall_sum_time)/torch.sum(overall_num.sum(dim=-2))\n",
    "        opt.zero_grad() \n",
    "        total_loss.backward()\n",
    "        opt.step()\n",
    "        overall_loss_train.extend([total_loss.data.item()])\n",
    "       \n",
    "    #print('|{}| Train_loss: {}'.format(datetime.now(), ' '.join(['{:.3f}'.format(x) for x in list(overall_loss_train) + [np.sum(overall_loss_train)]])))\n",
    "    print('|{}| Train_loss: {}'.format(datetime.now(), np.sum(overall_loss_train)/len(overall_loss_train)))\n",
    "    train_loss_sum.append(np.sum(overall_loss_train)/len(overall_loss_train))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        overall_num_list=[] \n",
    "        overall_x2y2_list=[]\n",
    "        for batched_graph, output_masks,snorm_n, snorm_e,last_vis_obj in tqdm(val_dataloader):\n",
    "            feats = batched_graph.ndata['x'].float().to(dev)\n",
    "            #reshape to have shape (B*V,T*C) [c1,c2,...,c6]\n",
    "            feats = feats.view(feats.shape[0],-1)\n",
    "            e_w = batched_graph.edata['w'].float().to(dev)\n",
    "            \n",
    "            #for GatedGCN\n",
    "            e_w= e_w.view(e_w.shape[0],1)\n",
    "            \n",
    "            labels= batched_graph.ndata['gt'][:,:,:].float().to(dev)\n",
    "            #labels = labels.view(labels.shape[0], -1)\n",
    "            pred = model(batched_graph, feats,e_w,snorm_n,snorm_e)\n",
    "            _, overall_num, x2y2_error = compute_RMSE_batch(pred, labels, output_masks[:,:,:])\n",
    "            #print(x2y2_error.shape)  #BV,T\n",
    "            overall_num_list.extend(overall_num.detach().cpu().numpy())\n",
    "            #print(overall_num.shape)  #BV,T\n",
    "            overall_x2y2_list.extend((x2y2_error**0.5).detach().cpu().numpy())  #RMSE para cada nodo en cada T\n",
    "            \n",
    "    overall_sum_time=np.sum(overall_x2y2_list,axis=0)  #BV,T->T RMSE medio en cada T\n",
    "    overall_num_time =np.sum(overall_num_list, axis=0)\n",
    "    overall_loss_val=(overall_sum_time / overall_num_time) #media del error de cada agente en cada frame\n",
    "\n",
    "    print('|{}| Val_loss: {}'.format(datetime.now(), ' '.join(['{:.3f}'.format(x) for x in list(overall_loss_val) + [np.sum(overall_loss_val)]])))\n",
    "    val_loss_sum.append(np.sum(overall_loss_val))\n",
    "    \n",
    "    if val_loss_prev < np.sum(overall_loss_val) and epoch !=0:\n",
    "        patience+=1\n",
    "        val_loss_prev = np.sum(overall_loss_val)\n",
    "    else:\n",
    "        patience = 0\n",
    "        val_loss_prev = np.sum(overall_loss_val)\n",
    "\n",
    "    \n",
    "    if patience > 2:\n",
    "        print(\"Early stopping: \")\n",
    "        print(\"Difference: {}\".format(val_loss_prev-np.sum(overall_loss_val)))\n",
    "        break\n",
    "    \n",
    "path=\"./models_checkpoints/gated.pth\"\n",
    "torch.save(model.state_dict(), path)\n",
    "print(\"Successfully saved to {}\".format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.ion() #Turn the interactive mode on\n",
    "#fig = plt.figure()\n",
    "epochs = list(range(33))\n",
    "#plt.plot(epochs,train_loss_sum, val_loss_sum)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epochs,train_loss_sum)\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epochs,val_loss_sum)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Val Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gcn_model = GCN(in_feats=18, hid_feats=256, out_feats=12).to(dev)\n",
    "gat_model = My_GAT(input_dim=18, hidden_dim=256, output_dim=12).to(dev)\n",
    "gat_model.load_state_dict(torch.load('./models_checkpoints/gat_b64_hid256.pth'))\n",
    "#gcn_model.load_state_dict(torch.load('./models_checkpoints/gcn_256_b64_ep40_embed.pth'))\n",
    "\n",
    "#print(gcn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11, 12])\n",
      "torch.Size([11, 6, 2]) torch.Size([11, 6, 1])\n",
      "[ 6.97032039 16.24366518 25.18899576 37.90354284 50.05630499 61.99487009] [3. 3. 3. 3. 3. 3.] [array([ 2.32344013,  5.41455506,  8.39633192, 12.63451428, 16.685435  ,\n",
      "       20.6649567 ])]\n"
     ]
    }
   ],
   "source": [
    "error_seg1=[]\n",
    "error_seg2=[]\n",
    "error_seg3=[]\n",
    "error_per_frame=[]\n",
    "with torch.no_grad():\n",
    "    i = val_id_list[1]\n",
    "    graph = dgl.from_scipy(spp.coo_matrix(adj[i][:last_vis_obj[i],:last_vis_obj[i]])).int().to(dev)\n",
    "    snorm_n, snorm_e, norm_d = collate(graph)\n",
    "    #graph = dgl.remove_self_loop(graph)\n",
    "    #graph = dgl.add_self_loop(graph)\n",
    "    distances = [xy_dist[i][graph.edges()[0][i]][graph.edges()[1][i]] for i in range(graph.num_edges())]\n",
    "    norm_distances = [(i-min(distances))/(max(distances)-min(distances)) if (max(distances)-min(distances))!=0 else (i-min(distances))/1.0 for i in distances]\n",
    "    norm_distances = [1/(i) if i!=0 else 1 for i in distances]\n",
    "    e_w=torch.tensor(norm_distances, dtype=torch.float32).to(dev)\n",
    "\n",
    "    features = node_features[i,:last_vis_obj[i]].to(dev)\n",
    "    features = features.view(features.shape[0],-1)\n",
    "    \n",
    "    #forward prop by using all nodes\n",
    "    pred = model(graph, features ,e_w,snorm_n, snorm_e)\n",
    "    print(pred.shape)\n",
    "    output_mask_i = output_mask[i,:last_vis_obj[i]].to(dev)\n",
    "    \n",
    "    pred=pred.view(pred.shape[0],6,-1)\n",
    "    print(pred.shape, output_mask_i.shape)\n",
    "    pred = pred*output_mask_i #Con esto ya quito del error aquellas filas donde no tengo datos.\n",
    "    \n",
    "    gt = node_labels[i,:last_vis_obj[i]].to(dev)\n",
    "    gt = gt*output_mask_i  #BV,T,C\n",
    "    \n",
    "    \n",
    "    x2y2_error=torch.sum(torch.abs(pred-gt)**2,dim=-1)  #x²+y²\n",
    "    xy_error=torch.sum(x2y2_error**0.5, dim=0).detach().cpu().numpy()  #raiz(x²+y²)   Error en cada frame\n",
    "    overall_num= output_mask_i.detach().cpu().numpy().sum(axis=-1).sum(axis=0) #numero de agentes en cada frame\n",
    "    \n",
    "    error_per_frame.append(xy_error / overall_num)\n",
    "    error_seg1.append(error_per_frame[:2])\n",
    "    error_seg2.append(error_per_frame[2:4])\n",
    "    error_seg3.append(error_per_frame[4:])\n",
    "    \n",
    "print(xy_error,overall_num,error_per_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230/230 [00:02<00:00, 82.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|2020-11-16 15:06:31.440298| Test_RMSE: 1.345 2.048 2.811 3.824 4.604 5.657 20.290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nwith torch.no_grad():\\n\\n    for batched_graph, output_masks,snorm_n, snorm_e,last_vis_obj in tqdm(test_dataloader):\\n        feats = batched_graph.ndata['x'].float().to(dev)\\n        feats = feats.view(feats.shape[0],-1)\\n        e_w = batched_graph.edata['w'].float().to(dev)\\n        labels= batched_graph.ndata['gt'].float().to(dev)\\n        pred = gat_model(batched_graph, feats,e_w,snorm_n,snorm_e)\\n        _, overall_num, x2y2_error = compute_RMSE_batch(pred, labels, output_masks)\\n        xy_error = (x2y2_error**0.5).detach().cpu().numpy() #BV,T\\n        overall_num = overall_num.detach().cpu().numpy()\\n        xy_s1_list.extend(xy_error[:,:2])\\n        xy_s2_list.extend(xy_error[:,2:4])\\n        xy_s3_list.extend(xy_error[:,4:])\\n        num_s1_list.extend(overall_num[:,:2])\\n        num_s2_list.extend(overall_num[:,2:4])\\n        num_s3_list.extend(overall_num[:,4:])\\n        \\n                \\noverall_sum_s1=np.sum(xy_s1_list,axis=0)  #BV,T->T\\noverall_sum_s2=np.sum(xy_s2_list,axis=0)\\noverall_sum_s3=np.sum(xy_s3_list,axis=0)\\noverall_num_s1 =np.sum(num_s1_list, axis=0)\\noverall_num_s2 =np.sum(num_s2_list, axis=0)\\noverall_num_s3 =np.sum(num_s3_list, axis=0)\\n    \\noverall_loss_s1=(overall_sum_s1 / overall_num_s1)#media del error de cada agente en cada frame\\noverall_loss_s2=(overall_sum\\n_s2 / overall_num_s2)\\noverall_loss_s3=(overall_sum_s3 / overall_num_s3)\\n\\nprint('Test_loss_sec1: average: {}'.format(overall_loss_s1))\\nprint('Test_loss_sec2: average: {}'.format(overall_loss_s2))\\nprint('Test_loss_sec3: average: {}'.format(overall_loss_s3))\\n      \\n\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "xy_s1_list= []\n",
    "xy_s2_list= []\n",
    "xy_s3_list= []\n",
    "num_s1_list= []\n",
    "num_s2_list= []\n",
    "num_s3_list= []\n",
    "\n",
    "gat_model.eval()\n",
    "with torch.no_grad():\n",
    "    overall_num_list=[] \n",
    "    overall_x2y2_list=[]\n",
    "    for batched_graph, output_masks,snorm_n, snorm_e,last_vis_obj in tqdm(test_dataloader):\n",
    "        feats = batched_graph.ndata['x'].float().to(dev)\n",
    "        #reshape to have shape (B*V,T*C) [c1,c2,...,c6]\n",
    "        feats = feats.view(feats.shape[0],-1)\n",
    "        e_w = batched_graph.edata['w'].float().to(dev)\n",
    "\n",
    "        #for GatedGCN\n",
    "        #e_w= e_w.view(e_w.shape[0],1)\n",
    "\n",
    "        labels= batched_graph.ndata['gt'][:,:,:].float().to(dev)\n",
    "        #labels = labels.view(labels.shape[0], -1)\n",
    "        pred = gat_model(batched_graph, feats,e_w,snorm_n,snorm_e)\n",
    "        _, overall_num, x2y2_error = compute_RMSE_batch(pred, labels, output_masks[:,:,:])\n",
    "        #print(x2y2_error.shape)  #BV,T\n",
    "        overall_num_list.extend(overall_num.detach().cpu().numpy())\n",
    "        #print(overall_num.shape)  #BV,T\n",
    "        overall_x2y2_list.extend((x2y2_error**0.5).detach().cpu().numpy())  #RMSE para cada nodo en cada T\n",
    "\n",
    "overall_sum_time=np.sum(overall_x2y2_list,axis=0)  #BV,T->T RMSE medio en cada T\n",
    "overall_num_time =np.sum(overall_num_list, axis=0)\n",
    "overall_loss_time=(overall_sum_time / overall_num_time) #media del error de cada agente en cada frame\n",
    "\n",
    "print('|{}| Test_RMSE: {}'.format(datetime.now(), ' '.join(['{:.3f}'.format(x) for x in list(overall_loss_time) + [np.sum(overall_loss_time)]])))\n",
    "\n",
    "'''\n",
    "with torch.no_grad():\n",
    "\n",
    "    for batched_graph, output_masks,snorm_n, snorm_e,last_vis_obj in tqdm(test_dataloader):\n",
    "        feats = batched_graph.ndata['x'].float().to(dev)\n",
    "        feats = feats.view(feats.shape[0],-1)\n",
    "        e_w = batched_graph.edata['w'].float().to(dev)\n",
    "        labels= batched_graph.ndata['gt'].float().to(dev)\n",
    "        pred = gat_model(batched_graph, feats,e_w,snorm_n,snorm_e)\n",
    "        _, overall_num, x2y2_error = compute_RMSE_batch(pred, labels, output_masks)\n",
    "        xy_error = (x2y2_error**0.5).detach().cpu().numpy() #BV,T\n",
    "        overall_num = overall_num.detach().cpu().numpy()\n",
    "        xy_s1_list.extend(xy_error[:,:2])\n",
    "        xy_s2_list.extend(xy_error[:,2:4])\n",
    "        xy_s3_list.extend(xy_error[:,4:])\n",
    "        num_s1_list.extend(overall_num[:,:2])\n",
    "        num_s2_list.extend(overall_num[:,2:4])\n",
    "        num_s3_list.extend(overall_num[:,4:])\n",
    "        \n",
    "                \n",
    "overall_sum_s1=np.sum(xy_s1_list,axis=0)  #BV,T->T\n",
    "overall_sum_s2=np.sum(xy_s2_list,axis=0)\n",
    "overall_sum_s3=np.sum(xy_s3_list,axis=0)\n",
    "overall_num_s1 =np.sum(num_s1_list, axis=0)\n",
    "overall_num_s2 =np.sum(num_s2_list, axis=0)\n",
    "overall_num_s3 =np.sum(num_s3_list, axis=0)\n",
    "    \n",
    "overall_loss_s1=(overall_sum_s1 / overall_num_s1)#media del error de cada agente en cada frame\n",
    "overall_loss_s2=(overall_sum\n",
    "_s2 / overall_num_s2)\n",
    "overall_loss_s3=(overall_sum_s3 / overall_num_s3)\n",
    "\n",
    "print('Test_loss_sec1: average: {}'.format(overall_loss_s1))\n",
    "print('Test_loss_sec2: average: {}'.format(overall_loss_s2))\n",
    "print('Test_loss_sec3: average: {}'.format(overall_loss_s3))\n",
    "      \n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pDL] *",
   "language": "python",
   "name": "conda-env-pDL-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
